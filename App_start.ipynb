{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application for Aesthetic with XAI \n",
    "by Lun Zhang, date: 2025-04-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import threading  # æ–°å¢çš„å¯¼å…¥\n",
    "from PIL import Image, ImageTk\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from omegaconf import OmegaConf\n",
    "# åœ¨æ–‡ä»¶é¡¶éƒ¨çš„å¯¼å…¥éƒ¨åˆ†æ·»åŠ \n",
    "from tkinter import filedialog  # æ–°å¢å¯¼å…¥\n",
    "# æ–¹å¼ä¸€ï¼šç›´æ¥å¯¼å…¥ï¼ˆæ¨èï¼‰\n",
    "# æ¨èåˆå¹¶å¯¼å…¥æ–¹å¼\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "\n",
    "\n",
    "from torch_aesthetics.models import * \n",
    "from omegaconf import OmegaConf\n",
    "from torch_aesthetics.cluster import *\n",
    "from torch_aesthetics.cluster_app import *\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "cfg = OmegaConf.load(\"configs/train.yaml\")\n",
    "# å…¶ä»–å¯¼å…¥...\n",
    "import os\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch_aesthetics\n",
    "from torch_aesthetics.models import *\n",
    "from torch_aesthetics.losses import *\n",
    "from torch_aesthetics.aadb import AADB, load_transforms\n",
    "from scipy import stats\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "from torch_aesthetics.kan_figure import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.model_targets import SumOfOutputOnKanNetFeaScore\n",
    "from torchvision.models import resnet50\n",
    "from pytorch_grad_cam import GradCAM, HiResCAM, GradCAMElementWise, GradCAMPlusPlus, XGradCAM, AblationCAM, ScoreCAM, EigenCAM, EigenGradCAM, LayerCAM, FullGrad\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchcam\n",
    "from torchcam.utils import overlay_mask\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "# æœ‰ GPU å°±ç”¨ GPUï¼Œæ²¡æœ‰å°±ç”¨ CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)\n",
    "\n",
    "dataset = AADB(\n",
    "    image_dir=cfg.data.image_dir,\n",
    "    labels_dir=cfg.data.labels_dir,\n",
    "    split=\"test\",\n",
    "    transforms=load_transforms(input_shape=cfg.data.input_shape)\n",
    ")\n",
    "\n",
    "model_Dev = RegressionNetwork_kan(\n",
    "    backbone='resnet50',\n",
    "    num_attributes=12,\n",
    "    pretrained=cfg.models.pretrained,\n",
    "    kan=None,\n",
    ")\n",
    "\n",
    "\n",
    "path_Reg = '/home/zl/ä¸‹è½½/input/pykan-master/models/Cam_Lin_reg/Cam_Lin_reg_res50_y_12_epoch_13_loss_0.0696_grid_1_score_0.5755565230299889.pt'\n",
    "\n",
    "\n",
    "model_Dev.load_state_dict(torch.load(path_Reg))\n",
    "\n",
    "model_Dev.to(cfg.device).to(torch.float32)\n",
    "\n",
    "i= 0\n",
    "\n",
    "def show_heatmap(img_tensor, class_id = 1,\n",
    "                 dataset = dataset, model_Dec_Pre = None):\n",
    "\n",
    "    input_tensor = img_tensor\n",
    "    print(input_tensor.shape)\n",
    "\n",
    "    y_pred = model_Dec_Pre.backbone.model(input_tensor)\n",
    "    print('y_pred.shape: ', y_pred.shape)\n",
    "\n",
    "    targets = [(ClassifierOutputTarget(class_id))]\n",
    "    # Grad-CAM\n",
    "    target_layers = [model_Dec_Pre.backbone.layer4[-1]]\n",
    "    cam = GradCAM(model = model_Dec_Pre.backbone.model, target_layers=target_layers)\n",
    "    cam_map = cam(input_tensor=input_tensor, targets=targets)[0] # ä¸åŠ å¹³æ»‘\n",
    "\n",
    "    # plt.imshow(cam_map)\n",
    "    # plt.show()\n",
    "    \n",
    "    img_pil = Image.open(dataset.files[i])\n",
    "    result = overlay_mask(img_pil, Image.fromarray(cam_map), alpha=0.6) # alphaè¶Šå°ï¼ŒåŸå›¾è¶Šæ·¡\n",
    "\n",
    "    return result\n",
    "\n",
    "# result = show_heatmap(feature_map = feature_map, img_tensor=img_tensor,\n",
    "#                       dataset=  dataset, model_Dec_Pre = model_Dec_Pre)\n",
    "# result\n",
    "\n",
    "def show_heatmap_12dim(img_tensor, class_id = 0,\n",
    "                 dataset = dataset, model_Dev = model_Dev, global_idx = 0):\n",
    "\n",
    "    input_tensor = img_tensor\n",
    "    # print(input_tensor.shape)\n",
    "\n",
    "    y_pred = model_Dev(input_tensor)\n",
    "    # print('y_pred.shape: ', y_pred.shape)\n",
    "    # print('y_pred: ', y_pred)\n",
    "\n",
    "    targets = [(ClassifierOutputTarget(class_id))]\n",
    "    # Grad-CAM\n",
    "    target_layers = [model_Dev.backbone.layer4[-1]]\n",
    "    \n",
    "    cam = GradCAM(model = model_Dev, target_layers=target_layers)\n",
    "    cam_map = cam(input_tensor=input_tensor, targets=targets)[0] # ä¸åŠ å¹³æ»‘\n",
    "\n",
    "    # plt.imshow(cam_map)\n",
    "    # plt.show()\n",
    "    \n",
    "    # ä¿®æ­£ä¸º\n",
    "    img_path = dataset.image_paths[global_idx]  # ä½¿ç”¨æ­£ç¡®çš„å±æ€§å\n",
    "    img_pil = Image.open(img_path)\n",
    "    result = overlay_mask(img_pil, Image.fromarray(cam_map), alpha=0.6) # alphaè¶Šå°ï¼ŒåŸå›¾è¶Šæ·¡\n",
    "\n",
    "    # # åœ¨ç”Ÿæˆresultåæ·»åŠ è°ƒè¯•ä»£ç \n",
    "    # print(\"å›¾åƒè°ƒè¯•ä¿¡æ¯:\") \n",
    "    # print(f\"1. åŸå§‹è·¯å¾„: {img_path}\")\n",
    "    # print(f\"3. åˆæˆå›¾æ¨¡å¼: {result.mode}\")\n",
    "    # print(f\"2. å›¾åƒå°ºå¯¸: {result}\")\n",
    "\n",
    "    # # æ˜¾ç¤ºå›¾åƒï¼ˆJupyterç¯å¢ƒï¼‰\n",
    "    # display(result)\n",
    "\n",
    "    # # ä¿å­˜ä¸´æ—¶æ–‡ä»¶æŸ¥çœ‹ï¼ˆé€šç”¨ï¼‰\n",
    "    # debug_path = f\"debug_{global_idx}.jpg\"\n",
    "    # result.save(debug_path)\n",
    "    # print(f\"4. å·²ä¿å­˜è°ƒè¯•æ–‡ä»¶: {debug_path}\")\n",
    "\n",
    "    # # æ£€æŸ¥åƒç´ å€¼èŒƒå›´\n",
    "    # print(f\"5. åƒç´ å€¼èŒƒå›´: {np.array(result).min()} - {np.array(result).max()}\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return result,cam_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid command name \"140360340153024start_queue_polling\"\n",
      "    while executing\n",
      "\"140360340153024start_queue_polling\"\n",
      "    (\"after\" script)\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zl/miniconda3/envs/d2l-zh/lib/python3.8/tkinter/__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/tmp/ipykernel_68056/596614032.py\", line 1410, in load_folder\n",
      "    self.path_label.config(text=f\"Current Path: {path[:50]}...\")\n",
      "AttributeError: 'ImageDatasetApp' object has no attribute 'path_label'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_normalized_features.shape: (25, 2048)\n",
      "centroids.shape: (10, 2048)\n",
      "3\n",
      "7\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zl/miniconda3/envs/d2l-zh/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/zl/miniconda3/envs/d2l-zh/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16, 12)\n",
      "(1, 9, 12)\n",
      "show_dataset\n",
      "3\n",
      "7\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n",
      "This image has a high overall clarity, with no focusing issues and no specific distortions. The lighting is sufficient, and the colors are monotonous. The main subjects are the birds on the lake surface and the tourists on the roadside, which are relatively clear. Most of the texture details are preserved. The composition is well-balanced, and the background is relatively clear. Therefore, the quality of this image is good.\n",
      "This image has a very good composition, with overall symmetry. The outline of the trees at the top of the image forms a heart shape, which adds a romantic and aesthetic appeal to the picture. The colors are vibrant and rich, with high contrast between the green of the trees and the blue of the sky. The overall clarity is also good. Therefore, the quality of this image is excellent.\n",
      "This image has a high overall clarity, with no focusing issues and no specific distortions. The lighting is sufficient, but the colors are monotonous. The main subjects are trees and a lawn, which are very clear and retain almost all texture details. The composition is well-balanced, and the background is very clear. Therefore, the quality of this image is excellent.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import threading  # æ–°å¢çš„å¯¼å…¥\n",
    "from PIL import Image, ImageTk\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from omegaconf import OmegaConf\n",
    "# åœ¨æ–‡ä»¶é¡¶éƒ¨çš„å¯¼å…¥éƒ¨åˆ†æ·»åŠ \n",
    "from tkinter import filedialog  # æ–°å¢å¯¼å…¥\n",
    "# æ–¹å¼ä¸€ï¼šç›´æ¥å¯¼å…¥ï¼ˆæ¨èï¼‰\n",
    "# æ¨èåˆå¹¶å¯¼å…¥æ–¹å¼\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "\n",
    "\n",
    "from torch_aesthetics.models import * \n",
    "from omegaconf import OmegaConf\n",
    "from torch_aesthetics.cluster import *\n",
    "from torch_aesthetics.cluster_app import *\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "cfg = OmegaConf.load(\"configs/train.yaml\")\n",
    "# å…¶ä»–å¯¼å…¥...\n",
    "import os\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch_aesthetics\n",
    "from torch_aesthetics.models import *\n",
    "from torch_aesthetics.losses import *\n",
    "from torch_aesthetics.aadb import AADB, load_transforms\n",
    "from scipy import stats\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "from torch_aesthetics.kan_figure import *\n",
    "import queue\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "class ImageDatasetApp:\n",
    "    def __init__(self, root):\n",
    "\n",
    "\n",
    "        self.root = root\n",
    "        self.root.title(\"IAAS\")\n",
    "        self.root.geometry(\"1200x800\")\n",
    "\n",
    "         # é¢œè‰²é…ç½®\n",
    "        self.colors = {\n",
    "            'primary': '#2c3e50',\n",
    "            'secondary': '#3498db',\n",
    "            'background': '#ecf0f1',\n",
    "            'text': '#2c3e50'\n",
    "        }\n",
    "        \n",
    "\n",
    "        # åˆ›å»ºæŒ‰é’®æ ·å¼\n",
    "        style = ttk.Style()\n",
    "        style.configure('Bold.TButton', font=('Arial', 12, 'bold'))\n",
    "        # å­—ä½“é…ç½®\n",
    "        self.fonts = {\n",
    "            'title': ('Segoe UI', 16, 'bold'),\n",
    "            'body': ('Segoe UI', 16),\n",
    "            'button': ('Segoe UI', 16, 'bold')\n",
    "        }\n",
    "        \n",
    "        # ä¸»å®¹å™¨å¸ƒå±€\n",
    "        self._setup_main_panes()\n",
    "\n",
    "        # åˆå§‹åŒ–å˜é‡\n",
    "        self.dataset = None\n",
    "        self.dataloader = None\n",
    "        self.current_path = \"\"\n",
    "        \n",
    "        # ç•Œé¢å¸ƒå±€\n",
    "        # self.create_widgets()\n",
    "        # self.setup_image_grid()\n",
    "\n",
    "         # ...åŸæœ‰åˆå§‹åŒ–ä»£ç ...\n",
    "        self.cluster_results = None\n",
    "        # self._add_cluster_controls()  # æ·»åŠ èšç±»æ§åˆ¶\n",
    "        # æ–°å¢è¯„åˆ†ç›¸å…³å±æ€§\n",
    "        self.scoring_model = None\n",
    "        self.scores = []\n",
    "        self._add_scoring_controls()  # æ·»åŠ è¯„åˆ†æ§åˆ¶\n",
    "\n",
    "        # æ–°å¢èšç±»è¯„åˆ†ç›¸å…³å±æ€§\n",
    "        self.cluster_scores = {}  # å­˜å‚¨å„èšç±»ç»„çš„è¯„åˆ†æ•°æ®\n",
    "        self._add_cluster_score_controls()\n",
    "        self.cluster_app = None\n",
    "\n",
    "        self.current_cluster_id = -1  # æ–°å¢ï¼šå½“å‰é€‰ä¸­èšç±»ID\n",
    "        self.sorted_index_list = []    # æ–°å¢ï¼šæ’åºåçš„å…¨å±€ç´¢å¼•åˆ—è¡¨\n",
    "        self.clusterID_get_indices = {}\n",
    "\n",
    "        # ä¿®æ”¹æ ‡ç­¾é¡µåˆå§‹åŒ–\n",
    "        self._init_analysis_tab()\n",
    "\n",
    "        self.heatmap_model = None  # æ–°å¢çƒ­åŠ›å›¾æ¨¡å‹å¼•ç”¨\n",
    "        self.heatmap_cache = {}    # æ–°å¢çƒ­åŠ›å›¾ç¼“å­˜\n",
    "\n",
    "        self.analysis_queue = queue.Queue()  # æ–°å¢æ¶ˆæ¯é˜Ÿåˆ—\n",
    "        self.root.after(100, self.start_queue_polling)  # å¯åŠ¨é˜Ÿåˆ—è½®è¯¢\n",
    "\n",
    "\n",
    "        self.analysis_texts = {}  # æ–°å¢å­—å…¸å­˜å‚¨å„å›¾ç‰‡åˆ†ææ¡†\n",
    "        self.current_active_idx = -1  # è¿½è¸ªå½“å‰æ˜¾ç¤ºç´¢å¼•\n",
    "        \n",
    "    # def _trigger_analysis(self, global_idx):\n",
    "    #     \"\"\"è§¦å‘å›¾ç‰‡åˆ†æ\"\"\"\n",
    "    #     # æ¸…ç©ºæ—§å†…å®¹å¹¶æ˜¾ç¤ºåŠ è½½çŠ¶æ€\n",
    "    #     self.analysis_text.delete(1.0, tk.END)\n",
    "    #     self.analysis_text.insert(tk.END, \"åˆ†æä¸­ï¼Œè¯·ç¨å€™...\")\n",
    "    #     self.analysis_text.update()\n",
    "        \n",
    "    #     # åœ¨åå°çº¿ç¨‹æ‰§è¡Œåˆ†æ\n",
    "    #     threading.Thread(\n",
    "    #         target=self._async_analyze_image,\n",
    "    #         args=(global_idx,),\n",
    "    #         daemon=True\n",
    "    #     ).start()\n",
    "\n",
    "\n",
    "\n",
    "    def _async_analyze_image(self, global_idx):\n",
    "        \"\"\"å¸¦ç´¢å¼•çš„å¼‚æ­¥åˆ†æ\"\"\"\n",
    "        try:\n",
    "            image_path = self.dataset.image_paths[global_idx]\n",
    "            result = self.analyze_image(image_path)\n",
    "            self.analysis_queue.put((global_idx, result))  # ä¿®æ”¹ä¸ºå‘é€å…ƒç»„\n",
    "        except Exception as e:\n",
    "            error_msg = f\"åˆ†æå¤±è´¥: {str(e)}\"\n",
    "            self.analysis_queue.put((global_idx, error_msg))\n",
    "\n",
    "    def _update_analysis_result(self, global_idx, result):\n",
    "        \"\"\"å®‰å…¨æ›´æ–°æŒ‡å®šæ–‡æœ¬æ¡†\"\"\"\n",
    "        if global_idx != self.current_active_idx:\n",
    "            return  # é˜²æ­¢æ˜¾ç¤ºé”™ä½\n",
    "        \n",
    "        text_widget = self.analysis_texts.get(global_idx)\n",
    "        if text_widget:\n",
    "            text_widget.config(state=tk.NORMAL)\n",
    "            text_widget.delete(1.0, tk.END)\n",
    "            text_widget.insert(tk.END, result)\n",
    "            text_widget.see(tk.END)\n",
    "            text_widget.config(state=tk.DISABLED)\n",
    "\n",
    "    def start_queue_polling(self):\n",
    "        \"\"\"ä¿®æ”¹åçš„é˜Ÿåˆ—è½®è¯¢\"\"\"\n",
    "        try:\n",
    "            while True:\n",
    "                global_idx, result = self.analysis_queue.get_nowait()\n",
    "                self._update_analysis_result(global_idx, result)\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        finally:\n",
    "            self.root.after(100, self.start_queue_polling)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def analyze_image(self, image_path):\n",
    "        \"\"\"Kimi APIåˆ†æå®ç°\"\"\"\n",
    "        # åˆ›å»º OpenAI å®¢æˆ·ç«¯å®ä¾‹\n",
    "        client = OpenAI(\n",
    "            api_key=\"sk-xbY97ZgZ1K3A2dQXG2f3hknjpDS1DSjphOnS72Caa8X4R5jX\",\n",
    "            base_url=\"https://api.moonshot.cn/v1\"\n",
    "        )\n",
    "\n",
    "        # å›¾ç‰‡ç¼–ç å¤„ç†\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            image_data = image_file.read()\n",
    "            image_base64 = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "            image_url = f\"data:image/{os.path.splitext(image_path)[1][1:]};base64,{image_base64}\"\n",
    "\n",
    "        # æ„å»ºæ¶ˆæ¯\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a professional photography critic, analyzing image aesthetics from composition, color, lighting, theme, and balance\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "                    {\"type\": \"text\", \"text\": \"Please analyze the aesthetic features of this image\"}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # å‘é€è¯·æ±‚\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"moonshot-v1-8k-vision-preview\",\n",
    "            messages=messages\n",
    "        )\n",
    "        print(response.choices[0].message.content)\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "    def _init_analysis_tab(self):\n",
    "        \"\"\"åˆå§‹åŒ–åˆ†ææ ‡ç­¾é¡µ\"\"\"\n",
    "        # æ¸…ç©ºæ—§å†…å®¹\n",
    "        for widget in self.aesth_tab.winfo_children():\n",
    "            widget.destroy()\n",
    "        \n",
    "        # åˆ›å»ºå›ºå®šæ»šåŠ¨ç³»ç»Ÿ\n",
    "        self.analysis_canvas = tk.Canvas(self.aesth_tab, bg=self.colors['background'])\n",
    "        scroll_y = ttk.Scrollbar(self.aesth_tab, orient=tk.VERTICAL, command=self.analysis_canvas.yview)\n",
    "        scroll_x = ttk.Scrollbar(self.aesth_tab, orient=tk.HORIZONTAL, command=self.analysis_canvas.xview)\n",
    "        \n",
    "        self.analysis_canvas.configure(\n",
    "            yscrollcommand=scroll_y.set,\n",
    "            xscrollcommand=scroll_x.set\n",
    "        )\n",
    "        \n",
    "        # å¸ƒå±€æ»šåŠ¨æ¡\n",
    "        scroll_x.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "        scroll_y.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        self.analysis_canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # åˆ›å»ºå†…å®¹å®¹å™¨\n",
    "        self.analysis_container = ttk.Frame(self.analysis_canvas)\n",
    "        self.analysis_canvas.create_window((0,0), window=self.analysis_container, anchor=tk.NW)\n",
    "        self.analysis_container.bind(\"<Configure>\", \n",
    "            lambda e: self.analysis_canvas.configure(scrollregion=self.analysis_canvas.bbox(\"all\")))\n",
    "\n",
    "    def _add_cluster_score_controls(self):\n",
    "        \"\"\"Add cluster scoring control components\"\"\"\n",
    "        score_frame = ttk.LabelFrame(self.control_panel, text=\"Cluster Scoring\")\n",
    "        score_frame.pack(pady=10, padx=5, fill=tk.X)\n",
    "\n",
    "        # Statistical metric selection\n",
    "        self.metric_var = tk.StringVar(value=\"mean\")\n",
    "        metrics = [(\"Mean\", \"mean\"), (\"Maximum\", \"max\"), (\"Minimum\", \"min\")]\n",
    "        for text, val in metrics:\n",
    "            ttk.Radiobutton(\n",
    "                score_frame,\n",
    "                text=text,\n",
    "                variable=self.metric_var,\n",
    "                value=val\n",
    "            ).pack(side=tk.LEFT, padx=2)\n",
    "\n",
    "        # Refresh button\n",
    "        ttk.Button(\n",
    "            score_frame,\n",
    "            text=\"Refresh Statistics\",\n",
    "            command=self.update_cluster_stats,\n",
    "            style='Accent.TButton'\n",
    "        ).pack(side=tk.RIGHT)\n",
    "        \n",
    "    def _add_scoring_controls(self):\n",
    "        \"\"\"Add scoring control components\"\"\"\n",
    "        scoring_frame = ttk.LabelFrame(self.control_panel, text=\"Image Scoring\")\n",
    "        scoring_frame.pack(pady=10, padx=5, fill=tk.X)\n",
    "\n",
    "        self.scoring_btn = ttk.Button(\n",
    "            scoring_frame,\n",
    "            text=\"â­ Generate Score\",\n",
    "            command=self.run_scoring,\n",
    "            style='Bold.TButton'\n",
    "        )\n",
    "        self.scoring_btn.pack(fill=tk.X, pady=3)\n",
    "\n",
    "        # Score display settings\n",
    "        self.show_score_var = tk.BooleanVar(value=True)\n",
    "        ttk.Checkbutton(\n",
    "            scoring_frame,\n",
    "            text=\"Show Detailed Attributes\",\n",
    "            variable=self.show_score_var,\n",
    "            command=self.toggle_score_display\n",
    "        ).pack(anchor=tk.W)\n",
    "\n",
    "\n",
    "\n",
    "    def run_scoring(self):\n",
    "        \"\"\"æ‰§è¡Œè¯„åˆ†æ“ä½œ\"\"\"\n",
    "        if not self.dataset:\n",
    "            messagebox.showwarning(\"è­¦å‘Š\", \"è¯·å…ˆåŠ è½½æ•°æ®é›†ï¼\")\n",
    "            return\n",
    "\n",
    "        if not self._load_scoring_model():\n",
    "            return\n",
    "\n",
    "        # ç¦ç”¨æŒ‰é’®é˜²æ­¢é‡å¤ç‚¹å‡»\n",
    "        self.scoring_btn.config(state=tk.DISABLED)\n",
    "        self.progress[\"value\"] = 0\n",
    "\n",
    "        # åœ¨åå°çº¿ç¨‹æ‰§è¡Œè¯„åˆ†\n",
    "        threading.Thread(\n",
    "            target=self._perform_scoring,\n",
    "            daemon=True\n",
    "        ).start()\n",
    "    \n",
    "    def _load_scoring_model(self):\n",
    "        \"\"\"åŠ è½½è¯„åˆ†æ¨¡å‹\"\"\"\n",
    "        try:\n",
    "            if self.scoring_model is None:\n",
    "                path_Reg = '/home/zl/ä¸‹è½½/input/pykan-master/models/Cam_Lin_reg/Cam_Lin_reg_res50_y_12_epoch_13_loss_0.0696_grid_1_score_0.5755565230299889.pt'\n",
    "                cfg = OmegaConf.load(\"configs/train.yaml\")\n",
    "                \n",
    "                self.scoring_model = RegressionNetwork_kan(\n",
    "                    backbone='resnet50',\n",
    "                    num_attributes=12,\n",
    "                    pretrained=cfg.models.pretrained,\n",
    "                    kan=None,\n",
    "                )\n",
    "                self.scoring_model.load_state_dict(torch.load(path_Reg))\n",
    "                self.scoring_model.to(cfg.device).float().eval()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"é”™è¯¯\", f\"åŠ è½½è¯„åˆ†æ¨¡å‹å¤±è´¥ï¼š{str(e)}\")\n",
    "            return False\n",
    "    \n",
    "\n",
    "\n",
    "     # ä¿®æ”¹åŸè¯„åˆ†æ–¹æ³•ä»¥æ”¯æŒèšç±»\n",
    "    def _perform_scoring(self):\n",
    "        \"\"\"æ‰§è¡Œè¯„åˆ†å¹¶å…³è”èšç±»ç´¢å¼•\"\"\"\n",
    "        try:\n",
    "            cfg = OmegaConf.load(\"configs/train.yaml\")\n",
    "            self.scores = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # æ”¹ä¸ºä½¿ç”¨æ•°æ®åŠ è½½å™¨æ‰¹é‡å¤„ç†\n",
    "                for batch in self.dataloader:\n",
    "                    inputs = batch.to(cfg.device)\n",
    "                    outputs = self.scoring_model(inputs).cpu().numpy()\n",
    "\n",
    "                    print(outputs.shape)\n",
    "                    \n",
    "                    # è½¬æ¢æ¯ä¸ªbatchçš„è¯„åˆ†\n",
    "                    attributes = ['Aesth_score', 'balancing_ele', 'color_harmony',\n",
    "                                'content', 'depth_of_field', 'light', 'motion_blur',\n",
    "                                'object', 'repetition', 'rule_of_thirds', 'symmetry',\n",
    "                                'vivid_color']\n",
    "\n",
    "                    # å¤„ç†ä¸‰ç»´è¾“å‡ºç»“æ„\n",
    "                    if outputs.ndim == 3:\n",
    "                        # å»é™¤æ‰¹æ¬¡ç»´åº¦å¹¶è½¬æ¢ä¸ºäºŒç»´æ•°ç»„\n",
    "                        outputs = outputs.squeeze(0)  # å½¢çŠ¶å˜ä¸º (16, 12)\n",
    "                    elif outputs.ndim != 2:\n",
    "                        raise ValueError(f\"æ— æ•ˆçš„è¾“å‡ºç»´åº¦ï¼š{outputs.ndim}ï¼Œé¢„æœŸ2Dæˆ–3Dæ•°ç»„\")\n",
    "\n",
    "                    # è½¬æ¢ä¸ºPythonåŸç”Ÿfloatç±»å‹\n",
    "                    processed_outputs = []\n",
    "                    for sample in outputs:\n",
    "                        if hasattr(sample, 'cpu'):  # å¤„ç†PyTorchå¼ é‡\n",
    "                            sample = sample.cpu().detach().numpy()\n",
    "                        if hasattr(sample, 'astype'):  # å¤„ç†numpyæ•°ç»„\n",
    "                            sample = sample.astype(float)\n",
    "                        processed_outputs.append([float(x) for x in sample])\n",
    "\n",
    "                    # æ„å»ºè¯„åˆ†å­—å…¸\n",
    "                    self.scores.extend(\n",
    "                        [dict(zip(attributes, sample)) \n",
    "                        for sample in processed_outputs]\n",
    "                    )\n",
    "\n",
    "                    # print(f\"æˆåŠŸæ·»åŠ  {len(processed_outputs)} ä¸ªæ ·æœ¬è¯„åˆ†\")\n",
    "                    # print(\"é¦–ä¸ªæ ·æœ¬è¯„åˆ†ç¤ºä¾‹ï¼š\", self.scores[0])\n",
    "\n",
    "\n",
    "                    \n",
    "                    # æ›´æ–°è¿›åº¦\n",
    "                    progress = len(self.scores) / len(self.dataset) * 100\n",
    "                    self.root.after(0, lambda v=progress: self.progress.config(value=v))\n",
    "            \n",
    "            # å…³è”èšç±»ç´¢å¼•\n",
    "            if hasattr(self.cluster_app, 'indices'):\n",
    "                self._analyze_cluster_scores()\n",
    "            \n",
    "            self.root.after(0, self._update_display_with_scores)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.root.after(0, lambda: messagebox.showerror(\"é”™è¯¯\", f\"è¯„åˆ†å¤±è´¥ï¼š{str(e)}\"))\n",
    "\n",
    "    def _analyze_cluster_scores(self):\n",
    "        \"\"\"åˆ†æå„èšç±»ç»„çš„è¯„åˆ†ç‰¹å¾\"\"\"\n",
    "        self.cluster_scores = {}\n",
    "        \n",
    "        for cluster_id in range(int(self.cluster_num.get())):\n",
    "            indices = self.cluster_app.indices[cluster_id]\n",
    "            valid_indices = [i for i in indices if i < len(self.scores)]\n",
    "            \n",
    "            # æ”¶é›†æ‰€æœ‰å±æ€§æ•°æ®\n",
    "            cluster_data = {\n",
    "                attr: [] for attr in self.scores[0].keys()\n",
    "            }\n",
    "            \n",
    "            for idx in valid_indices:\n",
    "                for attr, value in self.scores[idx].items():\n",
    "                    cluster_data[attr].append(value)\n",
    "            \n",
    "            # è®¡ç®—ç»Ÿè®¡é‡\n",
    "            self.cluster_scores[cluster_id] = {\n",
    "                attr: {\n",
    "                    'mean': np.mean(values),\n",
    "                    'std': np.std(values),\n",
    "                    'max': np.max(values),\n",
    "                    'min': np.min(values)\n",
    "                }\n",
    "                for attr, values in cluster_data.items()\n",
    "            }\n",
    "\n",
    "    def show_cluster_analysis(self):\n",
    "        \"\"\"æ˜¾ç¤ºèšç±»åˆ†ææŠ¥å‘Š\"\"\"\n",
    "        if not self.cluster_scores:\n",
    "            messagebox.showinfo(\"æç¤º\", \"è¯·å…ˆå®Œæˆèšç±»å’Œè¯„åˆ†\")\n",
    "            return\n",
    "        \n",
    "        analysis_win = tk.Toplevel()\n",
    "        analysis_win.title(\"èšç±»åˆ†ææŠ¥å‘Š\")\n",
    "        \n",
    "        # åˆ›å»ºè¡¨æ ¼\n",
    "        columns = ['å±æ€§'] + [f\"ç±»åˆ« {i}\" for i in self.cluster_scores.keys()]\n",
    "        tree = ttk.Treeview(analysis_win, columns=columns, show='headings')\n",
    "        \n",
    "        for col in columns:\n",
    "            tree.heading(col, text=col)\n",
    "            tree.column(col, width=100)\n",
    "        \n",
    "        # å¡«å……æ•°æ®\n",
    "        for attr in self.scores[0].keys():\n",
    "            row = [attr]\n",
    "            for cluster_id in self.cluster_scores:\n",
    "                stats = self.cluster_scores[cluster_id][attr]\n",
    "                row.append(f\"{stats['mean']:.2f} Â± {stats['std']:.2f}\")\n",
    "            tree.insert(\"\", tk.END, values=row)\n",
    "        \n",
    "        tree.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "    def _update_display_with_scores(self):\n",
    "        \"\"\"æ›´æ–°å¸¦è¯„åˆ†çš„æ˜¾ç¤º\"\"\"\n",
    "        self.show_dataset()\n",
    "\n",
    "    def toggle_score_display(self):\n",
    "        \"\"\"åˆ‡æ¢è¯„åˆ†æ˜¾ç¤ºæ¨¡å¼\"\"\"\n",
    "        if hasattr(self, 'scores'):\n",
    "            self.show_dataset()\n",
    "\n",
    "    def update_cluster_stats(self):\n",
    "        \"\"\"æ›´æ–°èšç±»ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "        if self.cluster_app is not None:\n",
    "            self._show_cluster_results()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def _setup_main_panes(self):\n",
    "        \"\"\"åˆ›å»ºä¸»å¸ƒå±€é¢æ¿\"\"\"\n",
    "        # ä½¿ç”¨PanedWindowå®ç°å¯è°ƒæ•´çš„åˆ†å‰²å¸ƒå±€\n",
    "        self.main_pane = tk.PanedWindow(self.root, orient=tk.HORIZONTAL, sashrelief=tk.RAISED)\n",
    "        self.main_pane.pack(fill=tk.BOTH, expand=1)\n",
    "\n",
    "        # å·¦ä¾§æ§åˆ¶é¢æ¿\n",
    "        self.control_panel = ttk.Frame(self.main_pane, width=300)\n",
    "        self.main_pane.add(self.control_panel)\n",
    "        \n",
    "        # å³ä¾§æ˜¾ç¤ºåŒºåŸŸ\n",
    "        self.display_panel = ttk.Frame(self.main_pane)\n",
    "        self.main_pane.add(self.display_panel, minsize=700)\n",
    "\n",
    "        # æ„å»ºå­ç»„ä»¶\n",
    "        self._build_control_panel()\n",
    "        self._build_display_panel()\n",
    "        self._build_status_bar()\n",
    "    \n",
    "    def _build_control_panel(self):\n",
    "        \"\"\"Build the left control panel\"\"\"\n",
    "        # Panel title\n",
    "        title_frame = ttk.Frame(self.control_panel)\n",
    "        title_frame.pack(pady=10, fill=tk.X)\n",
    "        ttk.Label(title_frame, text=\"Control Panel\", font=self.fonts['title'], \n",
    "                foreground=self.colors['primary']).pack()\n",
    "\n",
    "        # Function navigation\n",
    "        self._build_navigation()\n",
    "        \n",
    "        # Clustering controls\n",
    "        self._add_cluster_controls()\n",
    "        \n",
    "        # # System settings\n",
    "        # self._build_settings()\n",
    "\n",
    "    def _build_display_panel(self):\n",
    "        \"\"\"Build the right display area\"\"\"\n",
    "        # Tab component\n",
    "        self.notebook = ttk.Notebook(self.display_panel)\n",
    "        self.notebook.pack(fill=tk.BOTH, expand=1)\n",
    "        \n",
    "        # åˆ›å»ºæ ‡ç­¾é¡µæ ·å¼\n",
    "        style = ttk.Style()\n",
    "        style.configure('Tab.TNotebook.Tab', font=('Arial', 16, 'bold'))  # å¢åŠ å­—ä½“å¤§å°å¹¶åŠ ç²—\n",
    "        \n",
    "        # Aesthetic quality assessment\n",
    "        self.raw_tab = ttk.Frame(self.notebook)\n",
    "        self.notebook.add(self.raw_tab, text=\"Aesthetic Quality Assessment\")\n",
    "        \n",
    "        # Aesthetic analysis tab\n",
    "        self.aesth_tab = ttk.Frame(self.notebook)\n",
    "        self.notebook.add(self.aesth_tab, text=\"Aesthetic Attribute Analysis\")\n",
    "        \n",
    "        # # Clustering results tab\n",
    "        # self.cluster_tab = ttk.Frame(self.notebook)\n",
    "        # self.notebook.add(self.cluster_tab, text=\"Aesthetic Attribute Analysis\")\n",
    "        \n",
    "        # Initialize display components\n",
    "        self.setup_image_grid(self.raw_tab)  # Modified parameter for setup_image_grid\n",
    "\n",
    "    def _build_status_bar(self):\n",
    "        \"\"\"Build the bottom status bar\"\"\"\n",
    "        self.status_bar = ttk.Frame(self.root, height=22, relief=tk.SUNKEN)\n",
    "        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "        \n",
    "        self.status_label = ttk.Label(\n",
    "            self.status_bar, \n",
    "            text=\"Ready\",\n",
    "            anchor=tk.W,\n",
    "            font=('Segoe UI', 9)\n",
    "        )\n",
    "        self.status_label.pack(side=tk.LEFT, padx=4)\n",
    "        \n",
    "        ttk.Label(self.status_bar, text=\"Image Count:\").pack(side=tk.RIGHT, padx=4)\n",
    "        self.count_label = ttk.Label(self.status_bar, text=\"0\", width=6)\n",
    "        self.count_label.pack(side=tk.RIGHT)\n",
    "\n",
    "    def _build_navigation(self):\n",
    "        \"\"\"Build navigation button group\"\"\"\n",
    "        nav_frame = ttk.LabelFrame(self.control_panel, text=\"Data Operations\")\n",
    "        nav_frame.pack(pady=10, padx=5, fill=tk.X)\n",
    "\n",
    "\n",
    "        buttons = [\n",
    "            (\"Select Folder\", self.load_folder, \"ğŸ“‚\"),\n",
    "            (\"Create Dataset\", self.create_dataset, \"âš™ï¸\"),\n",
    "            (\"Show Data\", self.show_dataset, \"ğŸ‘ï¸\")\n",
    "        ]\n",
    "\n",
    "        for text, cmd, icon in buttons:\n",
    "            btn = ttk.Button(\n",
    "                nav_frame,\n",
    "                text=f\" {icon} {text}\",\n",
    "                command=cmd,\n",
    "                style='Bold.TButton',  # ä½¿ç”¨è‡ªå®šä¹‰æ ·å¼\n",
    "            )\n",
    "            btn.pack(pady=3, fill=tk.X)\n",
    "\n",
    "\n",
    "    def _add_cluster_controls(self):\n",
    "        \"\"\"Optimize cluster control components\"\"\"\n",
    "        cluster_frame = ttk.LabelFrame(self.control_panel, text=\"Cluster Settings\")\n",
    "        cluster_frame.pack(pady=10, padx=5, fill=tk.X)\n",
    "\n",
    "        # Add model selection button\n",
    "        ttk.Button(\n",
    "            cluster_frame,\n",
    "            text=\"Select Heatmap Model\",\n",
    "            command=self._select_heatmap_model,\n",
    "            style='Bold.TButton'\n",
    "        ).pack(pady=5, fill=tk.X)\n",
    "\n",
    "        # Parameter input\n",
    "        param_frame = ttk.Frame(cluster_frame)\n",
    "        param_frame.pack(fill=tk.X, pady=5)\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"Number of Clusters:\",style='Bold.TButton').pack(side=tk.LEFT)\n",
    "        self.cluster_num = ttk.Spinbox(\n",
    "            param_frame,\n",
    "            from_=2, to=20,\n",
    "            values=[2,3,5,8,10],\n",
    "            width=8\n",
    "        )\n",
    "        self.cluster_num.pack(side=tk.RIGHT)\n",
    "        self.cluster_num.set(10)\n",
    "\n",
    "        # Execute button\n",
    "        self.cluster_btn = ttk.Button(\n",
    "            cluster_frame,\n",
    "            text=\"â–¶ Start Clustering\",\n",
    "            command=self.run_clustering,\n",
    "            style='Bold.TButton'\n",
    "        )\n",
    "        self.cluster_btn.pack(pady=5, fill=tk.X)\n",
    "\n",
    "        # Progress bar\n",
    "        self.progress = ttk.Progressbar(\n",
    "            cluster_frame,\n",
    "            orient=tk.HORIZONTAL,\n",
    "            mode='determinate'\n",
    "        )\n",
    "        self.progress.pack(fill=tk.X, pady=5)\n",
    "\n",
    "\n",
    "    def run_clustering(self):\n",
    "        \"\"\"æ‰§è¡Œèšç±»æ“ä½œ\"\"\"\n",
    "        if not self.dataset:\n",
    "            messagebox.showwarning(\"è­¦å‘Š\", \"è¯·å…ˆåŠ è½½æ•°æ®é›†ï¼\")\n",
    "            return\n",
    "\n",
    "        # ç¦ç”¨æŒ‰é’®é˜²æ­¢é‡å¤ç‚¹å‡»\n",
    "        self.cluster_btn.config(state=tk.DISABLED)\n",
    "        self.progress[\"value\"] = 0\n",
    "\n",
    "        # åœ¨åå°çº¿ç¨‹æ‰§è¡Œèšç±»\n",
    "        threading.Thread(\n",
    "            target=self._perform_clustering,\n",
    "            daemon=True\n",
    "        ).start()\n",
    "\n",
    "    def _perform_clustering(self):\n",
    "        \"\"\"å®é™…æ‰§è¡Œèšç±»çš„æ–¹æ³•\"\"\"\n",
    "\n",
    "        # åˆå§‹åŒ–æ¨¡å‹å’Œé…ç½®\n",
    "        cfg = OmegaConf.load(\"configs/train.yaml\")\n",
    "        self.cfg = cfg\n",
    "        model = resnet34_Network_cluster(\n",
    "            backbone=cfg.models.backbone,\n",
    "            num_attributes=cfg.data.num_attributes,\n",
    "            pretrained=cfg.models.pretrained\n",
    "        ).to(cfg.device).float()\n",
    "\n",
    "        # åˆ›å»ºèšç±»å®ä¾‹\n",
    "        cluster_app = Cluster_App(\n",
    "            Dataset=self.dataset,\n",
    "            Data_loader=self.dataloader,\n",
    "            model=model,\n",
    "            cfg=cfg,\n",
    "            n_clusters=int(self.cluster_num.get())\n",
    "        )\n",
    "\n",
    "        # æ‰§è¡Œèšç±»å¹¶æ›´æ–°è¿›åº¦\n",
    "        # def update_progress(p):\n",
    "        #     self.progress[\"value\"] = p*100\n",
    "        #     self.root.update_idletasks()\n",
    "\n",
    "        self.cluster_app = cluster_app  # ä¿å­˜èšç±»å®ä¾‹\n",
    "        # self.cluster_results = cluster_app.run_clustering(\n",
    "        #     progress_callback=update_progress\n",
    "        # )\n",
    "\n",
    "        # æ˜¾ç¤ºèšç±»ç»“æœ\n",
    "        self.root.after(0, self._show_cluster_results)\n",
    "\n",
    "\n",
    "\n",
    "    def _show_cluster_results(self):\n",
    "        \"\"\"æ˜¾ç¤ºå¸¦è¯„åˆ†çš„èšç±»ç»“æœ\"\"\"\n",
    "        self.clear_display()\n",
    "        \n",
    "        for cluster_id in range(int(self.cluster_num.get())):\n",
    "            dataset_cluster, self.indices = self.cluster_app.giveAndPlot_kmeansImage(\n",
    "                target_element=cluster_id\n",
    "            )\n",
    "            \n",
    "            # åˆ›å»ºèšç±»åˆ†ç»„å®¹å™¨\n",
    "            cluster_frame = tk.LabelFrame(\n",
    "                self.main_container,\n",
    "                text=self._get_cluster_header(cluster_id, indices = self.indices),\n",
    "                bg='#F0F0F0',\n",
    "                font=('Arial', 10, 'bold')\n",
    "            )\n",
    "            cluster_frame.pack(pady=10, fill=tk.BOTH, expand=True)\n",
    "            \n",
    "            # åˆ›å»ºç½‘æ ¼å¸ƒå±€\n",
    "            grid_frame = tk.Frame(cluster_frame)\n",
    "            grid_frame.pack(padx=5, pady=5)\n",
    "            \n",
    "            # æ˜¾ç¤ºå›¾ç‰‡å’Œè¯„åˆ†\n",
    "            # idx = 0,1,2,3\n",
    "            for idx in range(min(8, len(dataset_cluster))):  # æ¯ç±»æ˜¾ç¤º4å¼ \n",
    "                self._create_cluster_cell(grid_frame, dataset_cluster, idx, cluster_id)\n",
    "        \n",
    "    def _get_cluster_header(self, cluster_id, indices):\n",
    "        \"\"\"ç”Ÿæˆå¸¦ç»Ÿè®¡ä¿¡æ¯çš„æ ‡é¢˜ï¼ˆå¢åŠ ç©ºæ•°æ®ä¿æŠ¤ï¼‰\"\"\"\n",
    "        if isinstance(indices, np.ndarray):\n",
    "            indices = indices.tolist()\n",
    "\n",
    "        # ä½¿ç”¨æ˜ç¡®çš„é•¿åº¦æ£€æŸ¥ä»£æ›¿çœŸå€¼åˆ¤æ–­\n",
    "        has_scores = bool(self.scores)\n",
    "        has_indices = len(indices) > 0\n",
    "        \n",
    "        base_title = f\"ç±»åˆ« {cluster_id}\"\n",
    "        if has_indices:\n",
    "            base_title += f\" (å…±{len(indices)}å¼ )\"\n",
    "        \n",
    "        if not has_scores or not has_indices:\n",
    "            return base_title\n",
    "        \n",
    "        # è¿‡æ»¤æœ‰æ•ˆç´¢å¼•ï¼ˆå¤„ç†numpyç´¢å¼•ï¼‰\n",
    "        valid_indices = [i for i in indices if i < len(self.scores)]\n",
    "        if not valid_indices:\n",
    "            return base_title + \" | æ— æœ‰æ•ˆè¯„åˆ†\"\n",
    "        \n",
    "        # è·å–å½“å‰ç°‡çš„æ‰€æœ‰è¯„åˆ†\n",
    "        cluster_scores = [self.scores[i] for i in valid_indices]\n",
    "        \n",
    "        try:\n",
    "            # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡ï¼ˆå¢åŠ å¼‚å¸¸æ•è·ï¼‰\n",
    "            metric = self.metric_var.get()\n",
    "            scores = [s['Aesth_score'] for s in cluster_scores if 'Aesth_score' in s]\n",
    "            \n",
    "            if not scores:\n",
    "                return base_title + \" | ç¼ºå°‘è¯„åˆ†å­—æ®µ\"\n",
    "                \n",
    "            avg_score = np.mean(scores)\n",
    "            max_score = np.max(scores)\n",
    "            min_score = np.min(scores)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ç»Ÿè®¡è®¡ç®—é”™è¯¯: {str(e)}\")\n",
    "            return base_title + \" | ç»Ÿè®¡é”™è¯¯\"\n",
    "\n",
    "        stats_text = {\n",
    "            'mean': f\"å¹³å‡åˆ†: {avg_score:.2f}\",\n",
    "            'max': f\"æœ€é«˜åˆ†: {max_score:.2f}\",\n",
    "            'min': f\"æœ€ä½åˆ†: {min_score:.2f}\"\n",
    "        }\n",
    "        \n",
    "        return f\"{base_title} | {stats_text.get(metric, '')}\"\n",
    "\n",
    "    def _create_cluster_cell(self, parent, dataset, idx, cluster_id):\n",
    "        \"\"\"åˆ›å»ºå¸¦è¯„åˆ†çš„èšç±»å•å…ƒæ ¼\"\"\"\n",
    "        cell = tk.Frame(\n",
    "            parent,\n",
    "            width=220,\n",
    "            height=240,\n",
    "            bg='white',\n",
    "            relief='groove',\n",
    "            borderwidth=2\n",
    "        )\n",
    "        cell.grid(row=idx//4, column=idx%4, padx=5, pady=5)\n",
    "        \n",
    "\n",
    "        # æ˜¾ç¤ºå›¾åƒ\n",
    "        \n",
    "\n",
    "        if self.scores:\n",
    "            pass\n",
    "        else:\n",
    "            tensor = dataset[idx]\n",
    "            img = self.tensor_to_pil(tensor)\n",
    "            img.thumbnail((200, 200))\n",
    "            photo = ImageTk.PhotoImage(img)\n",
    "            img_label = tk.Label(cell, image=photo)\n",
    "            img_label.image = photo\n",
    "            img_label.pack(pady=2)\n",
    "        \n",
    "\n",
    "        \n",
    "        # æ˜¾ç¤ºè¯„åˆ†ä¿¡æ¯\n",
    "        # ç›®å‰æ¥çœ‹è¯„åˆ†æ•°æ®å’Œå›¾ç‰‡ä¸èƒ½å¯¹åº”\n",
    "        if self.scores:\n",
    "            # è½¬æ¢ä¸ºç¨³å®šçš„åˆ—è¡¨ç»“æ„\n",
    "            index_list = np.array(self.indices).flatten().tolist()\n",
    "\n",
    "\n",
    "            # æŒ‰Aesthè¯„åˆ†é™åºæ’åº\n",
    "            sorted_index_list = sorted(\n",
    "                index_list,\n",
    "                key=lambda x: self.scores[x]['Aesth_score'],\n",
    "                reverse=True\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            self.clusterID_get_indices[cluster_id] = sorted_index_list\n",
    "            # print('')\n",
    "            # print('self.clusterID_get_indices[cluster_id]ï¼š',self.clusterID_get_indices[cluster_id])\n",
    "\n",
    "            # # éªŒè¯æ’åºç»“æœç¤ºä¾‹\n",
    "            # print(\"æ’åºå‰é¦–å…ƒç´ :\", index_list[0], \"è¯„åˆ†:\", self.scores[index_list[0]]['Aesth_score'])\n",
    "            # print(\"æ’åºåé¦–å…ƒç´ :\", sorted_index_list[0], \"è¯„åˆ†:\", self.scores[sorted_index_list[0]]['Aesth_score'])\n",
    "\n",
    "\n",
    "            \n",
    "            # å®‰å…¨è·å–å…¨å±€ç´¢å¼•\n",
    "            global_idx = sorted_index_list[idx]\n",
    "\n",
    "\n",
    "            \n",
    "            # æ˜¾ç¤ºå…¨å±€ç´¢å¼•ï¼ˆæ–°å¢éƒ¨åˆ†ï¼‰\n",
    "            index_label = tk.Label(cell, \n",
    "                                text=f\"Dataset Index: {global_idx}\",\n",
    "                                font=('Courier', 9, 'bold'),\n",
    "                                bg='#F0F0F0')\n",
    "            index_label.pack(side=tk.TOP, fill=tk.X)\n",
    "\n",
    "            # 2. å†æ·»åŠ å›¾ç‰‡\n",
    "            tensor = self.dataset[global_idx]\n",
    "            img = self.tensor_to_pil(tensor)\n",
    "            img.thumbnail((200, 200))\n",
    "            photo = ImageTk.PhotoImage(img)\n",
    "            img_label = tk.Label(cell, image=photo)\n",
    "            img_label.image = photo\n",
    "            img_label.pack(pady=2)\n",
    "\n",
    "\n",
    "            # è·å–è¯„åˆ†æ•°æ®\n",
    "            score_info = self.scores[global_idx]\n",
    "            \n",
    "            # ä¸»è¯„åˆ†\n",
    "            score_text = f\"Aesth: {score_info['Aesth_score']:.2f}\"\n",
    "            tk.Label(cell,\n",
    "                    text=score_text,\n",
    "                    bg='#FFD700',\n",
    "                    font=('Arial', 9, 'bold')).pack(fill=tk.X)\n",
    "            \n",
    "            # å…³é”®å±æ€§\n",
    "            attr_frame = tk.Frame(cell, bg='white')\n",
    "            attr_frame.pack()\n",
    "            \n",
    "            # for attr in ['color_harmony', 'rule_of_thirds']:\n",
    "            #     tk.Label(attr_frame,\n",
    "            #             text=f\"{attr[:4]}:{score_info[attr]:.2f}\",\n",
    "            #             font=('Arial', 8),\n",
    "            #             bg='white').pack(side=tk.LEFT, padx=2)\n",
    "    \n",
    "\n",
    "        # åœ¨æ˜¾ç¤ºå›¾ç‰‡çš„éƒ¨åˆ†æ·»åŠ ç‚¹å‡»äº‹ä»¶ç»‘å®š\n",
    "        img_label.bind(\"<Button-1>\", lambda e, cid=cluster_id: self._on_cluster_click(cid))\n",
    "        return cell\n",
    "    \n",
    "    def _on_cluster_click(self, cluster_id):\n",
    "        \"\"\"å¤„ç†èšç±»ç‚¹å‡»äº‹ä»¶\"\"\"\n",
    "        self.current_cluster_id = cluster_id\n",
    "        self.notebook.select(self.aesth_tab)  # åˆ‡æ¢åˆ°å›ºå®šåˆ†ææ ‡ç­¾é¡µ\n",
    "        self._update_analysis_content()\n",
    "\n",
    "    def _update_analysis_content(self):\n",
    "        \"\"\"æ›´æ–°åˆ†ææ ‡ç­¾é¡µå†…å®¹ï¼ˆä½¿ç”¨å›ºå®šå®¹å™¨ï¼‰\"\"\"\n",
    "        # æ¸…ç©ºæ—§å†…å®¹\n",
    "        for widget in self.analysis_container.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "        # æ·»åŠ æ ‡é¢˜\n",
    "        ttk.Label(self.analysis_container, \n",
    "                text=f\"Cluster {self.current_cluster_id}\",\n",
    "                font=('Arial', 14, 'bold')).pack(pady=10)\n",
    "\n",
    "        # è·å–å¹¶æ’åºç´¢å¼•\n",
    "        indices = self.clusterID_get_indices[self.current_cluster_id]\n",
    "        sorted_indices = indices[:8]\n",
    "        # æ˜¾ç¤ºå›¾ç‰‡ç½‘æ ¼\n",
    "        grid_frame = ttk.Frame(self.analysis_container)\n",
    "        grid_frame.pack(pady=10)\n",
    "        \n",
    "        for idx, global_idx in enumerate(sorted_indices):\n",
    "            # print(\"attr-----------------\")\n",
    "            # print(\"sorted_indices:\", sorted_indices)\n",
    "            # print(\"global_idx:\", global_idx)\n",
    "            # print(\"idx:\", idx)\n",
    "            # print(\"sorted_indices[idx]:\", sorted_indices[idx])\n",
    "\n",
    "            self._create_analysis_image(grid_frame, global_idx, idx)\n",
    "            \n",
    "    def _create_analysis_image(self, parent, global_idx, position):\n",
    "        \"\"\"Create an analysis page image unit with heatmap\"\"\"\n",
    "        # Create the main container\n",
    "        cell = ttk.Frame(parent)\n",
    "        cell.grid(row=position, column=0, sticky=\"nsew\", padx=10, pady=10)\n",
    "        \n",
    "        # Create a Notebook for switchable content (increased size)\n",
    "        img_notebook = ttk.Notebook(cell, width=900, height=580)  # Increased size\n",
    "        img_notebook.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Original image tab\n",
    "        orig_frame = ttk.Frame(img_notebook)\n",
    "        self._create_base_image(orig_frame, global_idx)\n",
    "        img_notebook.add(orig_frame, text=\"Original Image\")\n",
    "\n",
    "        # Heatmap tab (3x5 layout)\n",
    "        heatmap_frame = ttk.Frame(img_notebook)\n",
    "        self._create_heatmap_content(heatmap_frame, global_idx)  # Modified layout method\n",
    "        img_notebook.add(heatmap_frame, text=\"Heatmap Analysis\")\n",
    "\n",
    "        return cell\n",
    "\n",
    "    def _create_base_image(self, parent, global_idx):\n",
    "        \"\"\"Create the base image display and integrate the analysis interface\"\"\"\n",
    "        # Main container: horizontally arrange the image and analysis interface\n",
    "        main_frame = ttk.Frame(parent)\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "        \n",
    "        # ================== Left-side image display area ===========# ...Omitted other code...\n",
    "\n",
    "\n",
    "        # ==== Modified code ====\n",
    "        img_frame = ttk.Frame(main_frame, width=300)\n",
    "        img_frame.pack(side=tk.LEFT, fill=tk.Y, padx=10, pady=10)\n",
    "        \n",
    "        # Display image\n",
    "        tensor = self.dataset[global_idx]\n",
    "        img = self.tensor_to_pil(tensor)\n",
    "        img.thumbnail((280, 280))  # Slightly increase thumbnail size\n",
    "        photo = ImageTk.PhotoImage(img)\n",
    "        \n",
    "        lbl = ttk.Label(img_frame, image=photo)\n",
    "        lbl.image = photo\n",
    "        lbl.pack(pady=5)\n",
    "        \n",
    "        # Bind image click event\n",
    "        lbl.bind(\"<Button-1>\", lambda e: self._trigger_analysis(global_idx))\n",
    "        \n",
    "        # ================== Right-side analysis interface area ===========# ...Omitted other code...\n",
    "\n",
    "\n",
    "        # ==== Modified code ====\n",
    "        analysis_frame = ttk.LabelFrame(\n",
    "            main_frame,\n",
    "            text=\"Aesthetic Analysis Results\",\n",
    "            padding=(10, 5),\n",
    "            style='Analysis.TLabelframe'\n",
    "        )\n",
    "        analysis_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True, padx=10)\n",
    "        # Create independent analysis textbox (no longer use self.analysis_text)\n",
    "        analysis_text = tk.Text(\n",
    "            analysis_frame,\n",
    "            wrap=tk.WORD,\n",
    "            height=15,\n",
    "            font=('Microsoft YaHei', 11),\n",
    "            bg='#F8F9FA',\n",
    "            relief=tk.FLAT\n",
    "        )\n",
    "\n",
    "        # Store in dictionary\n",
    "        self.analysis_texts[global_idx] = analysis_text\n",
    "        \n",
    "        # Configure scrollbar\n",
    "        scrollbar = ttk.Scrollbar(analysis_frame, command=analysis_text.yview)\n",
    "        analysis_text.configure(yscrollcommand=scrollbar.set)\n",
    "        \n",
    "        # Layout\n",
    "        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        analysis_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Analysis button\n",
    "        btn_frame = ttk.Frame(img_frame, padding=5)\n",
    "        btn_frame.pack(side=tk.BOTTOM, fill=tk.X, pady=5)\n",
    "        # Modify button callback\n",
    "        ttk.Button(\n",
    "            btn_frame,\n",
    "            text=\"â­ Start Analysis\",\n",
    "            command=lambda: self._trigger_analysis(global_idx),\n",
    "            style='Accent.TButton'\n",
    "        ).pack(side=tk.LEFT)\n",
    "        \n",
    "        ttk.Button(\n",
    "            btn_frame,\n",
    "            text=\"ğŸ—‘ï¸ Clear Results\",\n",
    "            command=lambda: analysis_text.delete(1.0, tk.END),\n",
    "            style='Secondary.TButton'\n",
    "        ).pack(side=tk.RIGHT)\n",
    "\n",
    "    def _trigger_analysis(self, global_idx):\n",
    "        \"\"\"Trigger analysis for the specified index image\"\"\"\n",
    "        # Update the current active index\n",
    "        self.current_active_idx = global_idx\n",
    "        \n",
    "        # Get the corresponding textbox\n",
    "        text_widget = self.analysis_texts.get(global_idx)\n",
    "        if not text_widget:\n",
    "            return\n",
    "        \n",
    "        # Clear old content\n",
    "        text_widget.delete(1.0, tk.END)\n",
    "        text_widget.insert(tk.END, \"Analyzing, please wait...\")\n",
    "        text_widget.update()\n",
    "        \n",
    "        # Start asynchronous analysis\n",
    "        threading.Thread(\n",
    "            target=self._async_analyze_image,\n",
    "            args=(global_idx,),\n",
    "            daemon=True\n",
    "        ).start()\n",
    "\n",
    "\n",
    "    def _create_heatmap_content(self, parent, global_idx):\n",
    "        \"\"\"åˆ›å»º3x5ç½‘æ ¼å¸ƒå±€çš„çƒ­åŠ›å›¾\"\"\"\n",
    "        main_frame = ttk.Frame(parent)\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # æ·»åŠ æ»šåŠ¨åŒºåŸŸ\n",
    "        canvas = tk.Canvas(main_frame)\n",
    "        scrollbar = ttk.Scrollbar(main_frame, orient=\"vertical\", command=canvas.yview)\n",
    "        canvas.configure(yscrollcommand=scrollbar.set)\n",
    "        \n",
    "        scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "        canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "        \n",
    "        container = ttk.Frame(canvas)\n",
    "        canvas.create_window((0,0), window=container, anchor=\"nw\")\n",
    "        \n",
    "        # ç”Ÿæˆçƒ­åŠ›å›¾å†…å®¹\n",
    "        if global_idx not in self.heatmap_cache:\n",
    "            self._generate_heatmaps(global_idx)\n",
    "        \n",
    "        # 3x5ç½‘æ ¼å¸ƒå±€\n",
    "        row, col = 0, 0\n",
    "        for idx, heatmap in enumerate(self.heatmap_cache[global_idx]):\n",
    "            frame = ttk.Frame(container)\n",
    "            frame.grid(row=row, column=col, padx=5, pady=5)\n",
    "            \n",
    "            # æ˜¾ç¤ºå•ä¸ªçƒ­åŠ›å›¾\n",
    "            self._show_single_heatmap(frame, idx, heatmap, global_idx)\n",
    "            \n",
    "            # æ›´æ–°ç½‘æ ¼ä½ç½®\n",
    "            col += 1\n",
    "            if col >= 5:  # æ¯è¡Œ5åˆ—\n",
    "                col = 0\n",
    "                row += 1\n",
    "        \n",
    "        # é…ç½®ç”»å¸ƒæ»šåŠ¨åŒºåŸŸ\n",
    "        container.update_idletasks()\n",
    "        canvas.config(scrollregion=canvas.bbox(\"all\"))\n",
    "        \n",
    "        # ç»‘å®šé¼ æ ‡æ»šè½®æ»šåŠ¨\n",
    "        canvas.bind(\"<MouseWheel>\", lambda e: canvas.yview_scroll(-1*(e.delta//120), \"units\"))\n",
    "\n",
    "    def generate_contour_overlay(heatmap, \n",
    "                                 original_image, \n",
    "                                 threshold=0.15, \n",
    "                                 contour_color=(0, 255, 0), \n",
    "                                 thickness=2):\n",
    "        \"\"\"\n",
    "        æ ¹æ®Grad-CAMçƒ­åŠ›å›¾çš„å½¢çŠ¶ç»˜åˆ¶è½®å»“å¹¶å åŠ åœ¨åŸå§‹å›¾åƒä¸Šã€‚\n",
    "        \n",
    "        å‚æ•°ï¼š\n",
    "            heatmap (numpy.ndarray): Grad-CAMçƒ­åŠ›å›¾ï¼Œé€šå¸¸æ˜¯äºŒç»´æ•°ç»„ã€‚\n",
    "            original_image (numpy.ndarray): åŸå§‹è¾“å…¥å›¾åƒã€‚\n",
    "            threshold (float): äºŒå€¼åŒ–çš„é˜ˆå€¼ï¼ŒèŒƒå›´åœ¨[0, 1]ä¹‹é—´ï¼Œé»˜è®¤ä¸º0.15ã€‚\n",
    "            contour_color (tuple): è½®å»“é¢œè‰²ï¼ŒBGRæ ¼å¼ï¼Œé»˜è®¤ä¸ºç»¿è‰²ã€‚\n",
    "            thickness (int): è½®å»“çº¿æ¡çš„åšåº¦ï¼Œé»˜è®¤ä¸º2ã€‚\n",
    "        \n",
    "        è¿”å›ï¼š\n",
    "            numpy.ndarray: ç»˜åˆ¶äº†è½®å»“çš„åŸå§‹å›¾åƒã€‚\n",
    "        \"\"\"\n",
    "        # ç¡®ä¿çƒ­åŠ›å›¾æ˜¯äºŒç»´çš„\n",
    "        if heatmap.ndim != 2:\n",
    "            raise ValueError(\"çƒ­åŠ›å›¾åº”è¯¥æ˜¯äºŒç»´çš„\")\n",
    "        \n",
    "        # å½’ä¸€åŒ–çƒ­åŠ›å›¾åˆ°0-1èŒƒå›´\n",
    "        heatmap = (heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap) + 1e-8)\n",
    "        \n",
    "        # åº”ç”¨é˜ˆå€¼ï¼Œç”ŸæˆäºŒå€¼å›¾\n",
    "        binary_map = heatmap > threshold\n",
    "        \n",
    "        # æŸ¥æ‰¾è¿é€šåŒºåŸŸ\n",
    "        contours, _ = cv2.findContours(binary_map.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # åœ¨åŸå§‹å›¾åƒä¸Šç»˜åˆ¶è½®å»“\n",
    "        if contours:\n",
    "            cv2.drawContours(original_image, contours, -1, contour_color, thickness)\n",
    "        \n",
    "        return original_image\n",
    "    \n",
    "    def _generate_heatmaps(self, global_idx):\n",
    "        \"\"\"ç”Ÿæˆå¹¶ç¼“å­˜çƒ­åŠ›å›¾\"\"\"\n",
    "        # åŠ è½½æ¨¡å‹\n",
    "        if not self._load_heatmap_model():\n",
    "            return\n",
    "\n",
    "        # è·å–å›¾åƒæ•°æ®\n",
    "        img_tensor = self.dataset[global_idx].unsqueeze(0).to(self.cfg.device).float()\n",
    "        \n",
    "        # ç”Ÿæˆçƒ­åŠ›å›¾\n",
    "        Image_List = []\n",
    "        cam_map_List = []\n",
    "        \n",
    "        # åŸå§‹å›¾åƒ\n",
    "        img_np = np.array(self.tensor_to_pil(img_tensor.squeeze(0)))\n",
    "        Image_List.append(img_np)\n",
    "\n",
    "        # å„å±æ€§çƒ­åŠ›å›¾\n",
    "        for k in range(12):\n",
    "            image_result, cam_map = show_heatmap_12dim(\n",
    "                img_tensor=img_tensor,\n",
    "                class_id=k,\n",
    "                dataset=self.dataset,\n",
    "                model_Dev=self.heatmap_model,\n",
    "                global_idx=global_idx,\n",
    "            )\n",
    "            Image_List.append(image_result)\n",
    "            cam_map_List.append(cam_map)\n",
    "\n",
    "        # ç»¼åˆçƒ­åŠ›å›¾\n",
    "        sum_cam_map = np.zeros_like(cam_map_List[0])\n",
    "        for cam in cam_map_List[1:]:\n",
    "            sum_cam_map += cam\n",
    "        sum_cam_map = (sum_cam_map - sum_cam_map.min()) / (sum_cam_map.max() - sum_cam_map.min())\n",
    "        # ä¿®æ­£ä¸º\n",
    "        img_path = self.dataset.image_paths[global_idx]  # ä½¿ç”¨æ­£ç¡®çš„å±æ€§å\n",
    "        img_pil = Image.open(img_path)\n",
    "        sum_cam_map_image = overlay_mask(img_pil, Image.fromarray(cam_map), alpha=0.6) # alphaè¶Šå°ï¼ŒåŸå›¾è¶Šæ·¡\n",
    "        Image_List.append(sum_cam_map_image)\n",
    "\n",
    "        # ç”Ÿæˆå¸¦æœ‰è½®å»“çš„å›¾åƒ\n",
    "        image_with_contour = ImageDatasetApp.generate_contour_overlay(\n",
    "            cam_map_List[3], \n",
    "            img_np.copy(),  # ä½¿ç”¨åŸå§‹å›¾åƒçš„å‰¯æœ¬\n",
    "            threshold=0.5,  # è°ƒæ•´é˜ˆå€¼\n",
    "            contour_color=(255, 0, 0),  # çº¢è‰²è½®å»“\n",
    "            thickness=2  # è½®å»“çº¿åšåº¦\n",
    "        )\n",
    "        # print(\"ç”Ÿæˆè½®å»“: \",image_with_contour.shape)\n",
    "\n",
    "        # å°†ç”Ÿæˆçš„å›¾åƒæ·»åŠ åˆ° Image_List ä¸­\n",
    "        Image_List.append(image_with_contour)\n",
    "\n",
    "        # ç¼“å­˜ç»“æœ\n",
    "        self.heatmap_cache[global_idx] = Image_List\n",
    "        # print(f\"ç”Ÿæˆçƒ­åŠ›å›¾: {global_idx}\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def _show_single_heatmap(self, parent, idx, heatmap, global_idx):\n",
    "        \"\"\"æ˜¾ç¤ºå•ä¸ªçƒ­åŠ›å›¾å•å…ƒï¼ˆè°ƒæ•´ä¸ºé€‚åˆç½‘æ ¼å¸ƒå±€ï¼‰\"\"\"\n",
    "        frame = ttk.Frame(parent)\n",
    "        \n",
    "\n",
    "        # è°ƒæ•´æ˜¾ç¤ºå°ºå¯¸\n",
    "        display_size = 150  # ç¼©å°æ˜¾ç¤ºå°ºå¯¸ä»¥é€‚åº”ç½‘æ ¼\n",
    "        if isinstance(heatmap, np.ndarray):\n",
    "            img = Image.fromarray(heatmap).resize((display_size, display_size))\n",
    "        else:\n",
    "            img = heatmap.resize((display_size, display_size))\n",
    "        \n",
    "        photo = ImageTk.PhotoImage(img)\n",
    "        \n",
    "        # å±æ€§åç§°åˆ—è¡¨\n",
    "        attr_names = [\n",
    "            'Origin image',                # 0\n",
    "            'Aesth_score',        # 1 -> Aesth_score\n",
    "            'balancing_ele',     # 2 -> balancing_ele\n",
    "            'color_harmony',          # 3 -> color_harmony \n",
    "            'content',                # 4 -> content\n",
    "            'depth_of_field',         # 5 -> depth_of_field\n",
    "            'light',          # 6 -> light\n",
    "            'motion_blur',            # 7 -> motion_blur\n",
    "            'object',           # 8 -> object\n",
    "            'repetition',             # 9 -> repetition\n",
    "            'rule_of_thirds',         # 10 -> rule_of_thirds\n",
    "            'symmetry',               # 11 -> symmetry\n",
    "            'vivid_color',            # 12 -> vivid_color\n",
    "            'KAN_scores',                 # 13 (éœ€è¦ç¡®è®¤æ˜¯å¦å­˜åœ¨å¯¹åº”é”®)\n",
    "            'box'\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        # è·å–è¯„åˆ†æ–‡æœ¬\n",
    "        score_text = \"\"\n",
    "        if idx > 0:  # è·³è¿‡åŸå§‹å›¾åƒ\n",
    "            try:\n",
    "                scores = self.scores[global_idx]\n",
    "                # print(f\"è·å–è¯„åˆ†: scores\",scores)\n",
    "                if idx >= len(attr_names)-2:  # ç»¼åˆè¯„åˆ†\n",
    "                    score_text = ''\n",
    "                else:\n",
    "                    # # å°†å±æ€§åè½¬æ¢ä¸ºå°å†™ä½œä¸ºé”®ï¼ˆå¦‚Aesth -> aesthï¼‰\n",
    "                    key = attr_names[idx]\n",
    "                    score_text = f\"\\nscores: {scores[key]:.2f}\"\n",
    "            except (IndexError, KeyError) as e:\n",
    "                score_text = \"\\nscores: N/A\"\n",
    "                print(f\"è¯„åˆ†è·å–é”™è¯¯: {str(e)}\")\n",
    "\n",
    "        # åˆ›å»ºå¸¦è¯„åˆ†çš„æ ‡ç­¾\n",
    "        label = ttk.Label(\n",
    "            frame, \n",
    "            image=photo, \n",
    "            text=f\"{attr_names[idx]}{score_text}\",\n",
    "            compound=\"top\", \n",
    "            padding=2,\n",
    "            font=('Microsoft YaHei', 9),  # ä½¿ç”¨æ›´æ¸…æ™°çš„ä¸­æ–‡å­—ä½“\n",
    "            foreground='#333333'         # æ·±ç°è‰²æ–‡å­—\n",
    "        )\n",
    "        label.image = photo\n",
    "        label.pack()\n",
    "            \n",
    "\n",
    "        \n",
    "        frame.pack()\n",
    "\n",
    "    def _load_heatmap_model(self):\n",
    "            \"\"\"åŠ è½½çƒ­åŠ›å›¾ç”Ÿæˆæ¨¡å‹\"\"\"\n",
    "            try:\n",
    "                if self.heatmap_model is None:\n",
    "                    # å¦‚æœæœªé€‰æ‹©æ¨¡å‹è·¯å¾„ï¼Œåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„\n",
    "                    if not hasattr(self, 'heatmap_model_path'):\n",
    "                        self.heatmap_model_path = '/home/zl/ä¸‹è½½/input/pykan-master/models/Data_argu/Data_argu_4_depth_of_field_epoch_8_loss_0.0548_grid_1_score_0.41242475441672044.pt'\n",
    "\n",
    "                    # åˆå§‹åŒ–æ¨¡å‹\n",
    "                    self.heatmap_model = RegressionNetwork_kan(\n",
    "                        backbone=cfg.models.backbone,\n",
    "                        num_attributes=12,\n",
    "                        pretrained=cfg.models.pretrained,\n",
    "                        kan=None,\n",
    "                    ).to(self.cfg.device).eval()\n",
    "\n",
    "                    # åŠ è½½æ¨¡å‹æƒé‡\n",
    "                    self.heatmap_model.load_state_dict(torch.load(self.heatmap_model_path))\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"é”™è¯¯\", f\"åŠ è½½çƒ­åŠ›å›¾æ¨¡å‹å¤±è´¥ï¼š{str(e)}\")\n",
    "                return False\n",
    "\n",
    "    def _select_heatmap_model(self):\n",
    "        \"\"\"é€‰æ‹©çƒ­åŠ›å›¾æ¨¡å‹æ–‡ä»¶\"\"\"\n",
    "        initial_dir = '/home/zl/ä¸‹è½½/input/pykan-master/models'  # é»˜è®¤æ¨¡å‹ç›®å½•\n",
    "        filetypes = [('PyTorchæ¨¡å‹', '*.pt'), ('æ‰€æœ‰æ–‡ä»¶', '*.*')]\n",
    "        \n",
    "        filepath = filedialog.askopenfilename(\n",
    "            title=\"é€‰æ‹©çƒ­åŠ›å›¾æ¨¡å‹æ–‡ä»¶\",\n",
    "            initialdir=initial_dir,\n",
    "            filetypes=filetypes\n",
    "        )\n",
    "        \n",
    "        if filepath:\n",
    "            if not filepath.endswith('.pt'):\n",
    "                messagebox.showwarning(\"è­¦å‘Š\", \"è¯·é€‰æ‹©æœ‰æ•ˆçš„PyTorchæ¨¡å‹æ–‡ä»¶(.pt)\")\n",
    "                return\n",
    "            \n",
    "            # æ›´æ–°æ¨¡å‹è·¯å¾„\n",
    "            self.heatmap_model_path = filepath\n",
    "            self.heatmap_model = None  # é‡ç½®æ¨¡å‹å®ä¾‹\n",
    "            messagebox.showinfo(\"æç¤º\", \"æ¨¡å‹è·¯å¾„å·²æ›´æ–°ï¼Œä¸‹æ¬¡ç”Ÿæˆçƒ­åŠ›å›¾æ—¶å°†ä½¿ç”¨æ–°æ¨¡å‹\")\n",
    "\n",
    "\n",
    "    def _show_score_info(self, parent, global_idx):\n",
    "        \"\"\"æ˜¾ç¤ºè¯„åˆ†ä¿¡æ¯\"\"\"\n",
    "        score = self.scores[global_idx]\n",
    "        info = \"\\n\".join([\n",
    "            f\"Aesth: {score['Aesth_score']:.2f}\",\n",
    "            f\"Color: {score['color_harmony']:.2f}\",\n",
    "            f\"Composition: {score['rule_of_thirds']:.2f}\"\n",
    "        ])\n",
    "        \n",
    "        ttk.Label(parent,\n",
    "                text=info,\n",
    "                font=('Courier', 8),\n",
    "                relief=\"groove\").pack(fill=tk.X, pady=2)\n",
    "\n",
    "        \n",
    "    \n",
    "    def _show_score_info(self, parent, global_idx):\n",
    "        \"\"\"æ˜¾ç¤ºè¯„åˆ†ä¿¡æ¯\"\"\"\n",
    "        # è·å–è¯„åˆ†æ•°æ®\n",
    "        score_info = self.scores[global_idx]\n",
    "\n",
    "    def _update_analysis_tab(self):\n",
    "        \"\"\"æ›´æ–°åˆ†ææ ‡ç­¾é¡µå†…å®¹\"\"\"\n",
    "        # æ¸…ç©ºæ—§å†…å®¹\n",
    "        for widget in self.cluster_tab.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "        # åˆ›å»ºæ–°çš„æ»šåŠ¨å®¹å™¨\n",
    "        container = self.setup_image_grid(self.cluster_tab)\n",
    "        \n",
    "        # æ·»åŠ æ ‡é¢˜\n",
    "        ttk.Label(container, \n",
    "                text=f\"Cluster {self.current_cluster_id} è¯¦ç»†åˆ†æ\",\n",
    "                font=('Arial', 14, 'bold')).pack(pady=10)\n",
    "\n",
    "        # è·å–å½“å‰èšç±»çš„ç´¢å¼•\n",
    "        indices = self.clusterID_get_indices[self.current_cluster_id]\n",
    "        \n",
    "        # ç”Ÿæˆæ’åºåçš„ç´¢å¼•åˆ—è¡¨\n",
    "        self.sorted_index_list = sorted(\n",
    "            indices,\n",
    "            key=lambda x: self.scores[x]['Aesth_score'],\n",
    "            reverse=True\n",
    "        )[:8]\n",
    "\n",
    "        # æ˜¾ç¤ºæ’åºåçš„å›¾ç‰‡\n",
    "        grid_frame = ttk.Frame(container)\n",
    "        grid_frame.pack(pady=10)\n",
    "        \n",
    "        for idx, global_idx in enumerate(self.sorted_index_list):\n",
    "            self._create_analysis_image(grid_frame, global_idx, idx)\n",
    "\n",
    "\n",
    "    # ä¿®æ”¹åŸæœ‰æ˜¾ç¤ºæ–¹æ³•\n",
    "    def show_dataset(self):\n",
    "        \"\"\"æ˜¾ç¤ºæ•°æ®é›†ï¼ˆæ ¹æ®æ˜¯å¦èšç±»æ˜¾ç¤ºä¸åŒè§†å›¾ï¼‰\"\"\"\n",
    "\n",
    "        print(\"show_dataset\")\n",
    "        # ä¿®æ”¹åˆ¤æ–­æ¡ä»¶ä¸ºåŒæ—¶æ£€æŸ¥èšç±»ç»“æœå’Œè¯„åˆ†æ•°æ®\n",
    "        if self.cluster_app is not None:\n",
    "            # æ˜¾ç¤ºèšç±»ç»“æœ\n",
    "            self.root.after(0, self._show_cluster_results)\n",
    "\n",
    "            # self._show_cluster_results()\n",
    "        else:\n",
    "            self._show_raw_dataset()\n",
    "\n",
    "    def _show_raw_dataset(self):\n",
    "        \"\"\"æ˜¾ç¤ºåŸå§‹æ•°æ®é›†\"\"\"\n",
    "        \"\"\"æ˜¾ç¤ºæ•°æ®é›†ä¸­çš„å›¾ç‰‡\"\"\"\n",
    "        if not self.dataset:\n",
    "            messagebox.showwarning(\"è­¦å‘Š\", \"è¯·å…ˆåˆ›å»ºæ•°æ®é›†ï¼\")\n",
    "            return\n",
    "\n",
    "        self.clear_display()\n",
    "        self.create_image_grid(self.dataset)\n",
    "\n",
    "\n",
    "    def create_widgets(self):\n",
    "        \"\"\"åˆ›å»ºæ§åˆ¶é¢æ¿\"\"\"\n",
    "        control_frame = tk.Frame(self.root)\n",
    "        control_frame.pack(pady=10, fill=tk.X)\n",
    "\n",
    "        # è·¯å¾„æ˜¾ç¤º\n",
    "        self.path_label = tk.Label(control_frame, text=\"å½“å‰è·¯å¾„ï¼šæœªé€‰æ‹©\", width=60, anchor='w')\n",
    "        self.path_label.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # åŠŸèƒ½æŒ‰é’®\n",
    "        tk.Button(\n",
    "            control_frame,\n",
    "            text=\"é€‰æ‹©å›¾ç‰‡æ–‡ä»¶å¤¹\",\n",
    "            command=self.load_folder\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        tk.Button(\n",
    "            control_frame,\n",
    "            text=\"åˆ›å»ºæ•°æ®é›†\",\n",
    "            command=self.create_dataset\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        tk.Button(\n",
    "            control_frame,\n",
    "            text=\"æ˜¾ç¤ºæ•°æ®é›†\",\n",
    "            command=self.show_dataset\n",
    "        ).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "    def setup_image_grid(self, parent):\n",
    "        \"\"\"å›¾ç‰‡æ˜¾ç¤ºåŒºåŸŸä¼˜åŒ–\"\"\"\n",
    "        # æ»šåŠ¨ç³»ç»Ÿ\n",
    "        canvas = tk.Canvas(parent, bg=self.colors['background'])\n",
    "        scroll_y = ttk.Scrollbar(parent, orient=tk.VERTICAL, command=canvas.yview)\n",
    "        scroll_x = ttk.Scrollbar(parent, orient=tk.HORIZONTAL, command=canvas.xview)\n",
    "        \n",
    "        canvas.configure(\n",
    "            yscrollcommand=scroll_y.set,\n",
    "            xscrollcommand=scroll_x.set\n",
    "        )\n",
    "        \n",
    "        # å¸ƒå±€\n",
    "        scroll_x.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "        scroll_y.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # å›¾ç‰‡å®¹å™¨\n",
    "        self.main_container = ttk.Frame(canvas)\n",
    "        canvas.create_window((0,0), window=self.main_container, anchor=tk.NW)\n",
    "\n",
    "        # äº‹ä»¶ç»‘å®š\n",
    "        self.main_container.bind(\"<Configure>\", \n",
    "            lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "    \n",
    "    def _create_image_cell(self, parent, dataset, idx):\n",
    "        \"\"\"åˆ›å»ºå•ä¸ªå›¾ç‰‡å•å…ƒæ ¼\"\"\"\n",
    "        cell = tk.Frame(parent, width=150, height=170, \n",
    "                       borderwidth=1, relief='groove')\n",
    "        \n",
    "        try:\n",
    "            # æ˜¾ç¤ºå›¾åƒ\n",
    "            tensor = dataset[idx]\n",
    "            img = self.tensor_to_pil(tensor)\n",
    "            img.thumbnail((140, 140))\n",
    "            photo = ImageTk.PhotoImage(img)\n",
    "            \n",
    "            img_label = tk.Label(cell, image=photo)\n",
    "            img_label.image = photo\n",
    "            img_label.pack()\n",
    "            \n",
    "            # æ˜¾ç¤ºè¯„åˆ†\n",
    "            if idx < len(self.scores):\n",
    "                score = self.scores[idx]['Aesth_score']\n",
    "                tk.Label(cell, \n",
    "                        text=f\"Score: {score:.2f}\",\n",
    "                        bg='#FFD700', fg='black',\n",
    "                        font=('Arial', 9)).pack(fill=tk.X)\n",
    "                \n",
    "        except Exception as e:\n",
    "            tk.Label(cell, text=f\"é”™è¯¯\\n{str(e)[:15]}\", fg='red').pack()\n",
    "        \n",
    "        return cell\n",
    "\n",
    "\n",
    "    def load_folder(self):\n",
    "        \"\"\"Load Image Folder\"\"\"\n",
    "        path = filedialog.askdirectory()\n",
    "        if path:\n",
    "            self.current_path = path\n",
    "            self.path_label.config(text=f\"Current Path: {path[:50]}...\")\n",
    "            messagebox.showinfo(\"Info\", f\"Successfully loaded path: {path}\")\n",
    "\n",
    "    def create_dataset(self):\n",
    "        \"\"\"Create Dataset and Data Loader\"\"\"\n",
    "        if not self.current_path:\n",
    "            messagebox.showwarning(\"Warning\", \"Please select an image folder first!\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            self.dataset, self.dataloader = self.create_data_loader(self.current_path)\n",
    "            messagebox.showinfo(\"Success\", \n",
    "                f\"Dataset creation completed!\\n\"\n",
    "                f\"Number of samples: {len(self.dataset)}\\n\"\n",
    "                f\"Batch shape: {next(iter(self.dataloader)).shape}\")\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Failed to create dataset: {str(e)}\")\n",
    "\n",
    "        # def show_dataset(self):\n",
    "        #     \"\"\"æ˜¾ç¤ºæ•°æ®é›†ä¸­çš„å›¾ç‰‡\"\"\"\n",
    "        #     if not self.dataset:\n",
    "        #         messagebox.showwarning(\"è­¦å‘Š\", \"è¯·å…ˆåˆ›å»ºæ•°æ®é›†ï¼\")\n",
    "        #         return\n",
    "\n",
    "        #     self.clear_display()\n",
    "        #     self.create_image_grid(self.dataset)\n",
    "\n",
    "    # ä¿®æ”¹æ•°æ®é›†æ˜¾ç¤ºæ–¹æ³•\n",
    "    def create_image_grid(self, dataset):\n",
    "        \"\"\"åˆ›å»ºå¸¦è¯„åˆ†çš„å›¾ç‰‡ç½‘æ ¼\"\"\"\n",
    "        container = self.main_container\n",
    "        cols = 4  # å‡å°‘æ¯è¡Œåˆ—æ•°ä»¥å®¹çº³æ›´å¤šä¿¡æ¯\n",
    "        \n",
    "        for idx in range(len(dataset)):\n",
    "            row = idx // cols\n",
    "            col = idx % cols\n",
    "            \n",
    "            if col == 0:\n",
    "                row_frame = tk.Frame(container)\n",
    "                row_frame.pack(pady=5, anchor='w')\n",
    "\n",
    "            cell = self._create_image_cell(row_frame, dataset, idx)\n",
    "            cell.grid(row=0, column=col, padx=5)\n",
    "\n",
    "    def tensor_to_pil(self, tensor):\n",
    "        \"\"\"å°†å¼ é‡è½¬æ¢ä¸ºPILå›¾åƒ\"\"\"\n",
    "        # å¤„ç†ä¸åŒå½¢çŠ¶çš„å¼ é‡\n",
    "        if tensor.dim() == 4:\n",
    "            tensor = tensor.squeeze(0)\n",
    "        if tensor.size(0) > 3:\n",
    "            tensor = tensor[:3]\n",
    "        \n",
    "        # åæ ‡å‡†åŒ–\n",
    "        if tensor.min() < 0 or tensor.max() > 1:\n",
    "            tensor = (tensor - tensor.min()) / (tensor.max() - tensor.min())\n",
    "        \n",
    "        return T.ToPILImage()(tensor)\n",
    "\n",
    "    def clear_display(self):\n",
    "        \"\"\"æ¸…ç©ºæ˜¾ç¤ºåŒºåŸŸ\"\"\"\n",
    "        for widget in self.main_container.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "    def on_mousewheel(self, event):\n",
    "        \"\"\"å¤„ç†é¼ æ ‡æ»šè½®æ»šåŠ¨\"\"\"\n",
    "        self.canvas.yview_scroll(-1*(event.delta//120), \"units\")\n",
    "\n",
    "    @staticmethod\n",
    "    def create_data_loader(path):\n",
    "        \"\"\"åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆä»ç”¨æˆ·ä»£ç è¿ç§»ï¼‰\"\"\"\n",
    "        transform = T.Compose([\n",
    "            T.Resize((256, 256)),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        class CustomDataset(Dataset):\n",
    "            def __init__(self, root_dir, transform=None, max_samples=1000):\n",
    "                self.root_dir = root_dir\n",
    "                self.transform = transform\n",
    "                self.image_paths = self._load_paths(max_samples)\n",
    "\n",
    "            def _load_paths(self, max_samples):\n",
    "                valid_ext = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff')\n",
    "                return [\n",
    "                    os.path.join(self.root_dir, f) \n",
    "                    for f in os.listdir(self.root_dir)[:max_samples] \n",
    "                    if f.lower().endswith(valid_ext)\n",
    "                ]\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.image_paths)\n",
    "\n",
    "            def __getitem__(self, idx):\n",
    "                try:\n",
    "                    img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "                    return self.transform(img) if self.transform else img\n",
    "                except:\n",
    "                    return torch.zeros(3, 256, 256)\n",
    "\n",
    "        dataset = CustomDataset(path, transform=transform)\n",
    "        dataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "        return dataset, dataloader\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = ImageDatasetApp(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid command name \"140361536953792start_queue_polling\"\n",
      "    while executing\n",
      "\"140361536953792start_queue_polling\"\n",
      "    (\"after\" script)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import threading\n",
    "from PIL import Image, ImageTk\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from omegaconf import OmegaConf\n",
    "from torch_aesthetics.models import *\n",
    "from torch_aesthetics.cluster import *\n",
    "from torch_aesthetics.cluster_app import *\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "import queue\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import cv2\n",
    "from torch_aesthetics.kan_figure import *\n",
    "\n",
    "class ImageDatasetApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Image Dataset Processing System\")\n",
    "        self.root.geometry(\"1200x800\")\n",
    "\n",
    "        # Color configuration\n",
    "        self.colors = {\n",
    "            'primary': '#2c3e50',\n",
    "            'secondary': '#3498db',\n",
    "            'background': '#ecf0f1',\n",
    "            'text': '#2c3e50'\n",
    "        }\n",
    "        \n",
    "        # Font configuration (increased font size by two units)\n",
    "        self.fonts = {\n",
    "            'title': ('Segoe UI', 16, 'bold'),  # Increased from 14\n",
    "            'body': ('Segoe UI', 13),           # Increased from 11\n",
    "            'button': ('Segoe UI', 12, 'bold')  # Increased from 10\n",
    "        }\n",
    "        \n",
    "        # Main container layout\n",
    "        self._setup_main_panes()\n",
    "\n",
    "        # Initialize variables\n",
    "        self.dataset = None\n",
    "        self.dataloader = None\n",
    "        self.current_path = \"\"\n",
    "        \n",
    "        # Interface layout\n",
    "        self.cluster_results = None\n",
    "        self._add_scoring_controls()  # Add scoring controls\n",
    "        self._add_cluster_score_controls()\n",
    "        self.cluster_app = None\n",
    "\n",
    "        self.current_cluster_id = -1  # Added: Current selected cluster ID\n",
    "        self.sorted_index_list = []    # Added: Sorted global index list\n",
    "        self.clusterID_get_indices = {}\n",
    "\n",
    "        # Modified tab initialization\n",
    "        self._init_analysis_tab()\n",
    "\n",
    "        self.heatmap_model = None  # Added heatmap model reference\n",
    "        self.heatmap_cache = {}    # Added heatmap cache\n",
    "\n",
    "        self.analysis_queue = queue.Queue()  # Added message queue\n",
    "        self.root.after(100, self.start_queue_polling)  # Start queue polling\n",
    "\n",
    "        self.analysis_texts = {}  # Added dictionary to store analysis text boxes\n",
    "        self.current_active_idx = -1  # Track current display index\n",
    "        \n",
    "    def _async_analyze_image(self, global_idx):\n",
    "        \"\"\"Asynchronous analysis with index\"\"\"\n",
    "        try:\n",
    "            image_path = self.dataset.image_paths[global_idx]\n",
    "            result = self.analyze_image(image_path)\n",
    "            self.analysis_queue.put((global_idx, result))  # Modified to send tuple\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Analysis failed: {str(e)}\"\n",
    "            self.analysis_queue.put((global_idx, error_msg))\n",
    "\n",
    "    def _update_analysis_result(self, global_idx, result):\n",
    "        \"\"\"Safely update specified text box\"\"\"\n",
    "        if global_idx != self.current_active_idx:\n",
    "            return  # Prevent misalignment\n",
    "        \n",
    "        text_widget = self.analysis_texts.get(global_idx)\n",
    "        if text_widget:\n",
    "            text_widget.config(state=tk.NORMAL)\n",
    "            text_widget.delete(1.0, tk.END)\n",
    "            text_widget.insert(tk.END, result)\n",
    "            text_widget.see(tk.END)\n",
    "            text_widget.config(state=tk.DISABLED)\n",
    "\n",
    "    def start_queue_polling(self):\n",
    "        \"\"\"Modified queue polling\"\"\"\n",
    "        try:\n",
    "            while True:\n",
    "                global_idx, result = self.analysis_queue.get_nowait()\n",
    "                self._update_analysis_result(global_idx, result)\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        finally:\n",
    "            self.root.after(100, self.start_queue_polling)\n",
    "\n",
    "    def analyze_image(self, image_path):\n",
    "        \"\"\"Kimi API analysis implementation\"\"\"\n",
    "        # Create OpenAI client instance\n",
    "        client = OpenAI(\n",
    "            api_key=\"sk-xbY97ZgZ1K3A2dQXG2f3hknjpDS1DSjphOnS72Caa8X4R5jX\",\n",
    "            base_url=\"https://api.moonshot.cn/v1\"\n",
    "        )\n",
    "\n",
    "        # Image encoding processing\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            image_data = image_file.read()\n",
    "            image_base64 = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "            image_url = f\"data:image/{os.path.splitext(image_path)[1][1:]};base64,{image_base64}\"\n",
    "\n",
    "        # Build message\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a professional photography critic, analyze image aesthetics from composition, color, lighting, theme, and balance\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "                    {\"type\": \"text\", \"text\": \"Please analyze the aesthetic features of this image\"}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Send request\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"moonshot-v1-8k-vision-preview\",\n",
    "            messages=messages\n",
    "        )\n",
    "        print(response.choices[0].message.content)\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def _init_analysis_tab(self):\n",
    "        \"\"\"Initialize analysis tab\"\"\"\n",
    "        # Clear old content\n",
    "        for widget in self.aesth_tab.winfo_children():\n",
    "            widget.destroy()\n",
    "        \n",
    "        # Create fixed scroll system\n",
    "        self.analysis_canvas = tk.Canvas(self.aesth_tab, bg=self.colors['background'])\n",
    "        scroll_y = ttk.Scrollbar(self.aesth_tab, orient=tk.VERTICAL, command=self.analysis_canvas.yview)\n",
    "        scroll_x = ttk.Scrollbar(self.aesth_tab, orient=tk.HORIZONTAL, command=self.analysis_canvas.xview)\n",
    "        \n",
    "        self.analysis_canvas.configure(\n",
    "            yscrollcommand=scroll_y.set,\n",
    "            xscrollcommand=scroll_x.set\n",
    "        )\n",
    "        \n",
    "        # Layout scrollbars\n",
    "        scroll_x.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "        scroll_y.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        self.analysis_canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Create content container\n",
    "        self.analysis_container = ttk.Frame(self.analysis_canvas)\n",
    "        self.analysis_canvas.create_window((0,0), window=self.analysis_container, anchor=tk.NW)\n",
    "        self.analysis_container.bind(\"<Configure>\", \n",
    "            lambda e: self.analysis_canvas.configure(scrollregion=self.analysis_canvas.bbox(\"all\")))\n",
    "\n",
    "    def _add_cluster_score_controls(self):\n",
    "        \"\"\"Add cluster scoring control components\"\"\"\n",
    "        score_frame = ttk.LabelFrame(self.control_panel, text=\"Cluster Scoring\")\n",
    "        score_frame.pack(pady=10, padx=5, fill=tk.X)\n",
    "\n",
    "        # Statistical metric selection\n",
    "        self.metric_var = tk.StringVar(value=\"mean\")\n",
    "        metrics = [(\"Average\", \"mean\"), (\"Maximum\", \"max\"), (\"Minimum\", \"min\")]\n",
    "        for text, val in metrics:\n",
    "            ttk.Radiobutton(\n",
    "                score_frame,\n",
    "                text=text,\n",
    "                variable=self.metric_var,\n",
    "                value=val\n",
    "            ).pack(side=tk.LEFT, padx=2)\n",
    "\n",
    "        # Refresh button\n",
    "        ttk.Button(\n",
    "            score_frame,\n",
    "            text=\"Refresh Statistics\",\n",
    "            command=self.update_cluster_stats,\n",
    "            style='Accent.TButton'\n",
    "        ).pack(side=tk.RIGHT)\n",
    "    \n",
    "    def _add_scoring_controls(self):\n",
    "        \"\"\"Add scoring control components\"\"\"\n",
    "        scoring_frame = ttk.LabelFrame(self.control_panel, text=\"Image Scoring\")\n",
    "        scoring_frame.pack(pady=10, padx=5, fill=tk.X)\n",
    "\n",
    "        self.scoring_btn = ttk.Button(\n",
    "            scoring_frame,\n",
    "            text=\"â­ Generate Scoring\",\n",
    "            command=self.run_scoring,\n",
    "            style='Accent.TButton'\n",
    "        )\n",
    "        self.scoring_btn.pack(fill=tk.X, pady=3)\n",
    "\n",
    "        # Scoring display settings\n",
    "        self.show_score_var = tk.BooleanVar(value=True)\n",
    "        ttk.Checkbutton(\n",
    "            scoring_frame,\n",
    "            text=\"Show Detailed Attributes\",\n",
    "            variable=self.show_score_var,\n",
    "            command=self.toggle_score_display\n",
    "        ).pack(anchor=tk.W)\n",
    "\n",
    "    def run_scoring(self):\n",
    "        \"\"\"Perform scoring operation\"\"\"\n",
    "        if not self.dataset:\n",
    "            messagebox.showwarning(\"Warning\", \"Please load the dataset first!\")\n",
    "            return\n",
    "\n",
    "        if not self._load_scoring_model():\n",
    "            return\n",
    "\n",
    "        # Disable button to prevent repeated clicks\n",
    "        self.scoring_btn.config(state=tk.DISABLED)\n",
    "        self.progress[\"value\"] = 0\n",
    "\n",
    "        # Perform scoring in the background thread\n",
    "        threading.Thread(\n",
    "            target=self._perform_scoring,\n",
    "            daemon=True\n",
    "        ).start()\n",
    "    \n",
    "    def _load_scoring_model(self):\n",
    "        \"\"\"Load scoring model\"\"\"\n",
    "        try:\n",
    "            if self.scoring_model is None:\n",
    "                path_Reg = '/home/zl/ä¸‹è½½/input/pykan-master/models/Cam_Lin_reg/Cam_Lin_reg_res50_y_12_epoch_13_loss_0.0696_grid_1_score_0.5755565230299889.pt'\n",
    "                cfg = OmegaConf.load(\"configs/train.yaml\")\n",
    "                \n",
    "                self.scoring_model = RegressionNetwork_kan(\n",
    "                    backbone='resnet50',\n",
    "                    num_attributes=12,\n",
    "                    pretrained=cfg.models.pretrained,\n",
    "                    kan=None,\n",
    "                )\n",
    "                self.scoring_model.load_state_dict(torch.load(path_Reg))\n",
    "                self.scoring_model.to(cfg.device).float().eval()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Failed to load scoring model: {str(e)}\")\n",
    "            return False\n",
    "     # Modify original scoring method to support clustering\n",
    "    def _perform_scoring(self):\n",
    "        \"\"\"Perform scoring and associate cluster indices\"\"\"\n",
    "        try:\n",
    "            cfg = OmegaConf.load(\"configs/train.yaml\")\n",
    "            self.scores = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # Modified to use data loader for batch processing\n",
    "                for batch in self.dataloader:\n",
    "                    inputs = batch.to(cfg.device)\n",
    "                    outputs = self.scoring_model(inputs).cpu().numpy()\n",
    "\n",
    "                    print(outputs.shape)\n",
    "                    \n",
    "                    # Convert each batch's scoring\n",
    "                    attributes = ['Aesth_score', 'balancing_ele', 'color_harmony',\n",
    "                                'content', 'depth_of_field', 'light', 'motion_blur',\n",
    "                                'object', 'repetition', 'rule_of_thirds', 'symmetry',\n",
    "                                'vivid_color']\n",
    "\n",
    "                    # Process 3D output structure\n",
    "                    if outputs.ndim == 3:\n",
    "                        # Remove batch dimension and convert to 2D array\n",
    "                        outputs = outputs.squeeze(0)  # Shape becomes (16, 12)\n",
    "                    elif outputs.ndim != 2:\n",
    "                        raise ValueError(f\"Invalid output dimension: {outputs.ndim}, expected 2D or 3D array\")\n",
    "\n",
    "                    # Convert to Python native float type\n",
    "                    processed_outputs = []\n",
    "                    for sample in outputs:\n",
    "                        if hasattr(sample, 'cpu'):  # Handle PyTorch tensors\n",
    "                            sample = sample.cpu().detach().numpy()\n",
    "                        if hasattr(sample, 'astype'):  # Handle numpy arrays\n",
    "                            sample = sample.astype(float)\n",
    "                        processed_outputs.append([float(x) for x in sample])\n",
    "\n",
    "                    # Build score dictionary\n",
    "                    self.scores.extend(\n",
    "                        [dict(zip(attributes, sample)) \n",
    "                        for sample in processed_outputs]\n",
    "                    )\n",
    "\n",
    "                    # print(f\"Added {len(processed_outputs)} samples scoring\")\n",
    "                    # print(\"First sample scoring example: \", self.scores[0])\n",
    "\n",
    "\n",
    "                    \n",
    "                    # Update progress\n",
    "                    progress = len(self.scores) / len(self.dataset) * 100\n",
    "                    self.root.after(0, lambda v=progress: self.progress.config(value=v))\n",
    "            \n",
    "            # Associate cluster indices\n",
    "            if hasattr(self.cluster_app, 'indices'):\n",
    "                self._analyze_cluster_scores()\n",
    "            \n",
    "            self.root.after(0, self._update_display_with_scores)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.root.after(0, lambda: messagebox.showerror(\"Error\", f\"Scoring failed: {str(e)}\"))\n",
    "\n",
    "    def _analyze_cluster_scores(self):\n",
    "        \"\"\"Analyze scoring features of each cluster group\"\"\"\n",
    "        self.cluster_scores = {}\n",
    "        \n",
    "        for cluster_id in range(int(self.cluster_num.get())):\n",
    "            indices = self.cluster_app.indices[cluster_id]\n",
    "            valid_indices = [i for i in indices if i < len(self.scores)]\n",
    "            \n",
    "            # Collect all attribute data\n",
    "            cluster_data = {\n",
    "                attr: [] for attr in self.scores[0].keys()\n",
    "            }\n",
    "            \n",
    "            for idx in valid_indices:\n",
    "                for attr, value in self.scores[idx].items():\n",
    "                    cluster_data[attr].append(value)\n",
    "            \n",
    "            # Calculate statistics\n",
    "            self.cluster_scores[cluster_id] = {\n",
    "                attr: {\n",
    "                    'mean': np.mean(values),\n",
    "                    'std': np.std(values),\n",
    "                    'max': np.max(values),\n",
    "                    'min': np.min(values)\n",
    "                }\n",
    "                for attr, values in cluster_data.items()\n",
    "            }\n",
    "\n",
    "    def show_cluster_analysis(self):\n",
    "        \"\"\"Display cluster analysis report\"\"\"\n",
    "        if not self.cluster_scores:\n",
    "            messagebox.showinfo(\"Info\", \"Please complete clustering and scoring first\")\n",
    "            return\n",
    "        \n",
    "        analysis_win = tk.Toplevel()\n",
    "        analysis_win.title(\"Cluster Analysis Report\")\n",
    "        \n",
    "        # Create table\n",
    "        columns = ['Attribute'] + [f\"Cluster {i}\" for i in self.cluster_scores.keys()]\n",
    "        tree = ttk.Treeview(analysis_win, columns=columns, show='headings')\n",
    "        \n",
    "        for col in columns:\n",
    "            tree.heading(col, text=col)\n",
    "            tree.column(col, width=100)\n",
    "        \n",
    "        # Fill data\n",
    "        for attr in self.scores[0].keys():\n",
    "            row = [attr]\n",
    "            for cluster_id in self.cluster_scores:\n",
    "                stats = self.cluster_scores[cluster_id][attr]\n",
    "                row.append(f\"{stats['mean']:.2f} Â± {stats['std']:.2f}\")\n",
    "            tree.insert(\"\", tk.END, values=row)\n",
    "        \n",
    "        tree.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "    def _update_display_with_scores(self):\n",
    "        \"\"\"Update display with scoring\"\"\"\n",
    "        self.show_dataset()\n",
    "\n",
    "    def toggle_score_display(self):\n",
    "        \"\"\"Toggle scoring display mode\"\"\"\n",
    "        if hasattr(self, 'scores'):\n",
    "            self.show_dataset()\n",
    "\n",
    "    def update_cluster_stats(self):\n",
    "        \"\"\"Update cluster statistics\"\"\"\n",
    "        if self.cluster_app is not None:\n",
    "            self._show_cluster_results()\n",
    "    \n",
    "    def _setup_main_panes(self):\n",
    "        \"\"\"Create main layout panes\"\"\"\n",
    "        # Use PanedWindow for adjustable split layout\n",
    "        self.main_pane = tk.PanedWindow(self.root, orient=tk.HORIZONTAL, sashrelief=tk.RAISED)\n",
    "        self.main_pane.pack(fill=tk.BOTH, expand=1)\n",
    "\n",
    "        # Left control panel\n",
    "        self.control_panel = ttk.Frame(self.main_pane, width=300)\n",
    "        self.main_pane.add(self.control_panel)\n",
    "        \n",
    "        # Right display area\n",
    "        self.display_panel = ttk.Frame(self.main_pane)\n",
    "        self.main_pane.add(self.display_panel, minsize=600)\n",
    "\n",
    "        # Build sub-components\n",
    "        self._build_control_panel()\n",
    "        self._build_display_panel()\n",
    "        self._build_status_bar()\n",
    "    \n",
    "    def _build_control_panel(self):\n",
    "        \"\"\"Build left control panel\"\"\"\n",
    "        # Panel title\n",
    "        title_frame = ttk.Frame(self.control_panel)\n",
    "        title_frame.pack(pady=10, fill=tk.X)\n",
    "        ttk.Label(title_frame, text=\"Control Panel\", font=self.fonts['title'], \n",
    "                foreground=self.colors['primary']).pack()\n",
    "\n",
    "        # Function navigation\n",
    "        self._build_navigation()\n",
    "        \n",
    "        # Clustering control\n",
    "        self._add_cluster_controls()\n",
    "        \n",
    "        # # System settings\n",
    "        # self._build_settings()\n",
    "\n",
    "    def _build_display_panel(self):\n",
    "        \"\"\"Build right display area\"\"\"\n",
    "        # Tab component\n",
    "        self.notebook = ttk.Notebook(self.display_panel)\n",
    "        self.notebook.pack(fill=tk.BOTH, expand=1)\n",
    "        \n",
    "        # Aesthetic attribute analysis\n",
    "        self.raw_tab = ttk.Frame(self.notebook)\n",
    "        self.notebook.add(self.raw_tab, text=\"Raw Data Clustering\")\n",
    "        # Aesthetic analysis tab\n",
    "        self.aesth_tab = ttk.Frame(self.notebook)\n",
    "        self.notebook.add(self.aesth_tab, text=\"Aesthetic Attribute Analysis\")\n",
    "        \n",
    "        # # Clustering results tab\n",
    "        # self.cluster_tab = ttk.Frame(self.notebook)\n",
    "        # self.notebook.add(self.cluster_tab, text=\"Aesthetic Attribute Analysis\")\n",
    "        \n",
    "        # Initialize display components\n",
    "        self.setup_image_grid(self.raw_tab)  # Modified original setup_image_grid parameter\n",
    "\n",
    "    def _build_status_bar(self):\n",
    "        \"\"\"Build bottom status bar\"\"\"\n",
    "        self.status_bar = ttk.Frame(self.root, height=22, relief=tk.SUNKEN)\n",
    "        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "        \n",
    "        self.status_label = ttk.Label(\n",
    "            self.status_bar, \n",
    "            text=\"Ready\",\n",
    "            anchor=tk.W,\n",
    "            font=('Segoe UI', 10)\n",
    "        )\n",
    "        self.status_label.pack(side=tk.LEFT, padx=4)\n",
    "        \n",
    "        ttk.Label(self.status_bar, text=\"Number of Images:\").pack(side=tk.RIGHT, padx=4)\n",
    "        self.count_label = ttk.Label(self.status_bar, text=\"0\", width=6)\n",
    "        self.count_label.pack(side=tk.RIGHT)\n",
    "\n",
    "    def _build_navigation(self):\n",
    "        \"\"\"Build navigation button group\"\"\"\n",
    "        nav_frame = ttk.LabelFrame(self.control_panel, text=\"Data Operations\")\n",
    "        nav_frame.pack(pady=10, padx=5, fill=tk.X)\n",
    "\n",
    "        buttons = [\n",
    "            (\"Select Folder\", self.load_folder, \"ğŸ“‚\"),\n",
    "            (\"Create Dataset\", self.create_dataset, \"âš™ï¸\"),\n",
    "            (\"Show Data\", self.show_dataset, \"ğŸ‘ï¸\")\n",
    "        ]\n",
    "\n",
    "        for text, cmd, icon in buttons:\n",
    "            btn = ttk.Button(\n",
    "                nav_frame,\n",
    "                text=f\" {icon} {text}\",\n",
    "                command=cmd,\n",
    "                style='Accent.TButton',\n",
    "                \n",
    "            )\n",
    "            btn.pack(pady=3, fill=tk.X)\n",
    "\n",
    "\n",
    "    def _add_cluster_controls(self):\n",
    "        \"\"\"Clustering control components optimization\"\"\"\n",
    "        cluster_frame = ttk.LabelFrame(self.control_panel, text=\"Clustering Settings\")\n",
    "        cluster_frame.pack(pady=10, padx=5, fill=tk.X)\n",
    "\n",
    "\n",
    "         # Add model selection button\n",
    "        ttk.Button(\n",
    "            cluster_frame,\n",
    "            text=\"Select Heatmap Model\",\n",
    "            command=self._select_heatmap_model\n",
    "        ).pack(pady=5, fill=tk.X)\n",
    "\n",
    "        # Parameter input\n",
    "        param_frame = ttk.Frame(cluster_frame)\n",
    "        param_frame.pack(fill=tk.X, pady=5)\n",
    "        \n",
    "        ttk.Label(param_frame, text=\"Number of Clusters:\").pack(side=tk.LEFT)\n",
    "        self.cluster_num = ttk.Spinbox(\n",
    "            param_frame,\n",
    "            from_=2, to=20,\n",
    "            values=[2,3,5,8,10],\n",
    "            width=8\n",
    "        )\n",
    "        self.cluster_num.pack(side=tk.RIGHT)\n",
    "        self.cluster_num.set(5)\n",
    "\n",
    "        # Execute button\n",
    "        self.cluster_btn = ttk.Button(\n",
    "            cluster_frame,\n",
    "            text=\"â–¶ Start Clustering\",\n",
    "            command=self.run_clustering,\n",
    "            style='Accent.TButton'\n",
    "        )\n",
    "        self.cluster_btn.pack(pady=5, fill=tk.X)\n",
    "\n",
    "        # Progress bar\n",
    "        self.progress = ttk.Progressbar(\n",
    "            cluster_frame,\n",
    "            orient=tk.HORIZONTAL,\n",
    "            mode='determinate'\n",
    "        )\n",
    "        self.progress.pack(fill=tk.X, pady=5)\n",
    "\n",
    "\n",
    "    def run_clustering(self):\n",
    "        \"\"\"Perform clustering operation\"\"\"\n",
    "        if not self.dataset:\n",
    "            messagebox.showwarning(\"Warning\", \"Please load the dataset first!\")\n",
    "            return\n",
    "\n",
    "        # Disable button to prevent repeated clicks\n",
    "        self.cluster_btn.config(state=tk.DISABLED)\n",
    "        self.progress[\"value\"] = 0\n",
    "\n",
    "        # Perform clustering in the background thread\n",
    "        threading.Thread(\n",
    "            target=self._perform_clustering,\n",
    "            daemon=True\n",
    "        ).start()\n",
    "\n",
    "    def _perform_clustering(self):\n",
    "        \"\"\"Actual clustering execution method\"\"\"\n",
    "\n",
    "        # Initialize model and configuration\n",
    "        cfg = OmegaConf.load(\"configs/train.yaml\")\n",
    "        self.cfg = cfg\n",
    "        model = resnet34_Network_cluster(\n",
    "            backbone=cfg.models.backbone,\n",
    "            num_attributes=cfg.data.num_attributes,\n",
    "            pretrained=cfg.models.pretrained\n",
    "        ).to(cfg.device).float()\n",
    "\n",
    "        # Create clustering instance\n",
    "        cluster_app = Cluster_App(\n",
    "            Dataset=self.dataset,\n",
    "            Data_loader=self.dataloader,\n",
    "            model=model,\n",
    "            cfg=cfg,\n",
    "            n_clusters=int(self.cluster_num.get())\n",
    "        )\n",
    "\n",
    "        # Execute clustering and update progress\n",
    "        # def update_progress(p):\n",
    "        #     self.progress[\"value\"] = p*100\n",
    "        #     self.root.update_idletasks()\n",
    "\n",
    "        self.cluster_app = cluster_app  # Save clustering instance\n",
    "        # self.cluster_results = cluster_app.run_clustering(\n",
    "        #     progress_callback=update_progress\n",
    "        # )\n",
    "\n",
    "        # Display clustering results\n",
    "        self.root.after(0, self._show_cluster_results)\n",
    "\n",
    "\n",
    "\n",
    "    def _show_cluster_results(self):\n",
    "        \"\"\"Display clustering results with scoring\"\"\"\n",
    "        self.clear_display()\n",
    "        \n",
    "        for cluster_id in range(int(self.cluster_num.get())):\n",
    "            dataset_cluster, self.indices = self.cluster_app.giveAndPlot_kmeansImage(\n",
    "                target_element=cluster_id\n",
    "            )\n",
    "            \n",
    "            # Create cluster group container\n",
    "            cluster_frame = tk.LabelFrame(\n",
    "                self.main_container,\n",
    "                text=self._get_cluster_header(cluster_id, indices = self.indices),\n",
    "                bg='#F0F0F0',\n",
    "                font=('Arial', 12, 'bold')  # Increased font size\n",
    "            )\n",
    "            cluster_frame.pack(pady=10, fill=tk.BOTH, expand=True)\n",
    "            \n",
    "            # Create grid layout\n",
    "            grid_frame = tk.Frame(cluster_frame)\n",
    "            grid_frame.pack(padx=5, pady=5)\n",
    "            \n",
    "            # Display images and scores\n",
    "            # idx = 0,1,2,3\n",
    "            for idx in range(min(8, len(dataset_cluster))):  # Display 4 per cluster\n",
    "                self._create_cluster_cell(grid_frame, dataset_cluster, idx, cluster_id)\n",
    "        \n",
    "    def _get_cluster_header(self, cluster_id, indices):\n",
    "        \"\"\"Generate header with statistical information (added empty data protection)\"\"\"\n",
    "        if isinstance(indices, np.ndarray):\n",
    "            indices = indices.tolist()\n",
    "\n",
    "        # Use explicit length check instead of truth value judgment\n",
    "        has_scores = bool(self.scores)\n",
    "        has_indices = len(indices) > 0\n",
    "        \n",
    "        base_title = f\"Cluster {cluster_id}\"\n",
    "        if has_indices:\n",
    "            base_title += f\" (Total {len(indices)} images)\"\n",
    "        \n",
    "        if not has_scores or not has_indices:\n",
    "            return base_title\n",
    "        \n",
    "        # Filter valid indices (handle numpy indices)\n",
    "        valid_indices = [i for i in indices if i < len(self.scores)]\n",
    "        if not valid_indices:\n",
    "            return base_title + \" | No valid scores\"\n",
    "        \n",
    "        # Get all scores for the current cluster\n",
    "        cluster_scores = [self.scores[i] for i in valid_indices]\n",
    "        \n",
    "        try:\n",
    "            # Calculate statistical metrics (added exception handling)\n",
    "            metric = self.metric_var.get()\n",
    "            scores = [s['Aesth_score'] for s in cluster_scores if 'Aesth_score' in s]\n",
    "            \n",
    "            if not scores:\n",
    "                return base_title + \" | Missing score fields\"\n",
    "                \n",
    "            avg_score = np.mean(scores)\n",
    "            max_score = np.max(scores)\n",
    "            min_score = np.min(scores)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Statistical calculation error: {str(e)}\")\n",
    "            return base_title + \" | Statistical error\"\n",
    "\n",
    "        stats_text = {\n",
    "            'mean': f\"Average Score: {avg_score:.2f}\",\n",
    "            'max': f\"Highest Score: {max_score:.2f}\",\n",
    "            'min': f\"Lowest Score: {min_score:.2f}\"\n",
    "        }\n",
    "        \n",
    "        return f\"{base_title} | {stats_text.get(metric, '')}\"\n",
    "\n",
    "    def _create_cluster_cell(self, parent, dataset, idx, cluster_id):\n",
    "        \"\"\"Create cluster cell with scoring\"\"\"\n",
    "        cell = tk.Frame(\n",
    "            parent,\n",
    "            width=220,\n",
    "            height=240,\n",
    "            bg='white',\n",
    "            relief='groove',\n",
    "            borderwidth=2\n",
    "        )\n",
    "        cell.grid(row=idx//4, column=idx%4, padx=5, pady=5)\n",
    "        \n",
    "        # Display image\n",
    "        if self.scores:\n",
    "            pass\n",
    "        else:\n",
    "            tensor = dataset[idx]\n",
    "            img = self.tensor_to_pil(tensor)\n",
    "            img.thumbnail((200, 200))\n",
    "            photo = ImageTk.PhotoImage(img)\n",
    "            img_label = tk.Label(cell, image=photo)\n",
    "            img_label.image = photo\n",
    "            img_label.pack(pady=2)\n",
    "        \n",
    "        # Display scoring information\n",
    "        if self.scores:\n",
    "            # Convert to stable list structure\n",
    "            index_list = np.array(self.indices).flatten().tolist()\n",
    "            # Sort by Aesth score in descending order\n",
    "            sorted_index_list = sorted(\n",
    "                index_list,\n",
    "                key=lambda x: self.scores[x]['Aesth_score'],\n",
    "                reverse=True\n",
    "            )\n",
    "            self.clusterID_get_indices[cluster_id] = sorted_index_list\n",
    "            # Get global index safely\n",
    "            global_idx = sorted_index_list[idx]\n",
    "            \n",
    "            # Display global index\n",
    "            index_label = tk.Label(cell, \n",
    "                                text=f\"Dataset Index: {global_idx}\",\n",
    "                                font=('Courier', 9),  # Increased font size\n",
    "                                bg='#F0F0F0')\n",
    "            index_label.pack(side=tk.TOP, fill=tk.X)\n",
    "            \n",
    "            # Display image\n",
    "            tensor = self.dataset[global_idx]\n",
    "            img = self.tensor_to_pil(tensor)\n",
    "            img.thumbnail((200, 200))\n",
    "            photo = ImageTk.PhotoImage(img)\n",
    "            img_label = tk.Label(cell, image=photo)\n",
    "            img_label.image = photo\n",
    "            img_label.pack(pady=2)\n",
    "            \n",
    "            # Get scoring data\n",
    "            score_info = self.scores[global_idx]\n",
    "            \n",
    "            # Main score\n",
    "            score_text = f\"Aesth: {score_info['Aesth_score']:.2f}\"\n",
    "            tk.Label(cell,\n",
    "                    text=score_text,\n",
    "                    bg='#FFD700',\n",
    "                    font=('Arial', 11, 'bold')).pack(fill=tk.X)\n",
    "            \n",
    "            # Key attributes\n",
    "            attr_frame = tk.Frame(cell, bg='white')\n",
    "            attr_frame.pack()\n",
    "            \n",
    "            # for attr in ['color_harmony', 'rule_of_thirds']:\n",
    "            #     tk.Label(attr_frame,\n",
    "            #             text=f\"{attr[:4]}:{score_info[attr]:.2f}\",\n",
    "            #             font=('Arial', 9),  # Increased font size\n",
    "            #             bg='white').pack(side=tk.LEFT, padx=2)\n",
    "    \n",
    "\n",
    "        # Bind click event to display image\n",
    "        img_label.bind(\"<Button-1>\", lambda e, cid=cluster_id: self._on_cluster_click(cid))\n",
    "        return cell\n",
    "    \n",
    "    def _on_cluster_click(self, cluster_id):\n",
    "        \"\"\"Handle cluster click event\"\"\"\n",
    "        self.current_cluster_id = cluster_id\n",
    "        self.notebook.select(self.aesth_tab)  # Switch to fixed analysis tab\n",
    "        self._update_analysis_content()\n",
    "\n",
    "    def _update_analysis_content(self):\n",
    "        \"\"\"Update analysis tab content (using fixed container)\"\"\"\n",
    "        # Clear old content\n",
    "        for widget in self.analysis_container.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "        # Add title\n",
    "        ttk.Label(self.analysis_container, \n",
    "                text=f\"Cluster {self.current_cluster_id}\",\n",
    "                font=('Arial', 16, 'bold')).pack(pady=10)\n",
    "\n",
    "        # Get and sort indices\n",
    "        indices = self.clusterID_get_indices[self.current_cluster_id]\n",
    "        sorted_indices = indices[:8]\n",
    "        # Display image grid\n",
    "        grid_frame = ttk.Frame(self.analysis_container)\n",
    "        grid_frame.pack(pady=10)\n",
    "        \n",
    "        for idx, global_idx in enumerate(sorted_indices):\n",
    "            self._create_analysis_image(grid_frame, global_idx, idx)\n",
    "            \n",
    "    def _create_analysis_image(self, parent, global_idx, position):\n",
    "        \"\"\"Create analysis page image cell with heatmap\"\"\"\n",
    "        # Create main container\n",
    "        cell = ttk.Frame(parent)\n",
    "        cell.grid(row=position, column=0, sticky=\"nsew\", padx=10, pady=10)\n",
    "        \n",
    "        # Create notebook for switchable content (increased size)\n",
    "        img_notebook = ttk.Notebook(cell, width=900, height=580)  # Increased size\n",
    "        img_notebook.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Original image tab\n",
    "        orig_frame = ttk.Frame(img_notebook)\n",
    "        self._create_base_image(orig_frame, global_idx)\n",
    "        img_notebook.add(orig_frame, text=\"Original Image\")\n",
    "\n",
    "        # Heatmap tab (3x5 layout)\n",
    "        heatmap_frame = ttk.Frame(img_notebook)\n",
    "        self._create_heatmap_content(heatmap_frame, global_idx)  # Modified layout method\n",
    "        img_notebook.add(heatmap_frame, text=\"Heatmap Analysis\")\n",
    "\n",
    "        return cell\n",
    "\n",
    "    def _create_base_image(self, parent, global_idx):\n",
    "        \"\"\"Create base image display and integrate analysis interface\"\"\"\n",
    "        # Main container: horizontally arrange image and analysis interface\n",
    "        main_frame = ttk.Frame(parent)\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "        \n",
    "        # ================== Left image display area ===========# ...Omitted other code... \n",
    "\n",
    "\n",
    "        # ==== Modified code ====\n",
    "        img_frame = ttk.Frame(main_frame, width=300)\n",
    "        img_frame.pack(side=tk.LEFT, fill=tk.Y, padx=10, pady=10)\n",
    "        \n",
    "        # Display image\n",
    "        tensor = self.dataset[global_idx]\n",
    "        img = self.tensor_to_pil(tensor)\n",
    "        img.thumbnail((280, 280))  # Slightly increase thumbnail size\n",
    "        photo = ImageTk.PhotoImage(img)\n",
    "        \n",
    "        lbl = ttk.Label(img_frame, image=photo)\n",
    "        lbl.image = photo\n",
    "        lbl.pack(pady=5)\n",
    "        \n",
    "        # Bind click event to image label\n",
    "        lbl.bind(\"<Button-1>\", lambda e: self._trigger_analysis(global_idx))\n",
    "        \n",
    "        # ================== Right analysis interface area ===========# ...Omitted other code... \n",
    "\n",
    "\n",
    "        # ==== Modified code ====\n",
    "        analysis_frame = ttk.LabelFrame(\n",
    "            main_frame,\n",
    "            text=\"Aesthetic Analysis Results\",\n",
    "            padding=(10, 5),\n",
    "            style='Analysis.TLabelframe'\n",
    "        )\n",
    "        analysis_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True, padx=10)\n",
    "        # Create independent analysis text box (no longer use self.analysis_text)\n",
    "        analysis_text = tk.Text(\n",
    "            analysis_frame,\n",
    "            wrap=tk.WORD,\n",
    "            height=15,\n",
    "            font=('Microsoft YaHei', 13),  # Increased font size\n",
    "            bg='#F8F9FA',\n",
    "            relief=tk.FLAT\n",
    "        )\n",
    "\n",
    "        # Store in dictionary\n",
    "        self.analysis_texts[global_idx] = analysis_text\n",
    "        \n",
    "        # Configure scrollbar\n",
    "        scrollbar = ttk.Scrollbar(analysis_frame, command=analysis_text.yview)\n",
    "        analysis_text.configure(yscrollcommand=scrollbar.set)\n",
    "        \n",
    "        # Layout\n",
    "        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        analysis_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "                # Analysis button\n",
    "        btn_frame = ttk.Frame(img_frame, padding=5)\n",
    "        btn_frame.pack(side=tk.BOTTOM, fill=tk.X, pady=5)\n",
    "        # Modify button callback\n",
    "        ttk.Button(\n",
    "            btn_frame,\n",
    "            text=\"â­ Start Analysis\",\n",
    "            command=lambda: self._trigger_analysis(global_idx),\n",
    "            style='Accent.TButton'\n",
    "        ).pack(side=tk.LEFT)\n",
    "        \n",
    "        ttk.Button(\n",
    "            btn_frame,\n",
    "            text=\"ğŸ—‘ï¸ Clear Results\",\n",
    "            command=lambda: self.analysis_text.delete(1.0, tk.END),\n",
    "            style='Secondary.TButton'\n",
    "        ).pack(side=tk.RIGHT)\n",
    "\n",
    "    def _trigger_analysis(self, global_idx):\n",
    "        \"\"\"Trigger analysis for specified index image\"\"\"\n",
    "        # Update current active index\n",
    "        self.current_active_idx = global_idx\n",
    "        \n",
    "        # Get corresponding text box\n",
    "        text_widget = self.analysis_texts.get(global_idx)\n",
    "        if not text_widget:\n",
    "            return\n",
    "        \n",
    "        # Clear old content\n",
    "        text_widget.delete(1.0, tk.END)\n",
    "        text_widget.insert(tk.END, \"Analyzing, please wait...\")\n",
    "        text_widget.update()\n",
    "        \n",
    "        # Start asynchronous analysis\n",
    "        threading.Thread(\n",
    "            target=self._async_analyze_image,\n",
    "            args=(global_idx,),\n",
    "            daemon=True\n",
    "        ).start()\n",
    "\n",
    "\n",
    "    def _create_heatmap_content(self, parent, global_idx):\n",
    "        \"\"\"Create 3x5 grid layout for heatmaps\"\"\"\n",
    "        main_frame = ttk.Frame(parent)\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Add scroll area\n",
    "        canvas = tk.Canvas(main_frame)\n",
    "        scrollbar = ttk.Scrollbar(main_frame, orient=\"vertical\", command=canvas.yview)\n",
    "        canvas.configure(yscrollcommand=scrollbar.set)\n",
    "        \n",
    "        scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "        canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "        \n",
    "        container = ttk.Frame(canvas)\n",
    "        canvas.create_window((0,0), window=container, anchor=\"nw\")\n",
    "        \n",
    "        # Generate heatmap content\n",
    "        if global_idx not in self.heatmap_cache:\n",
    "            self._generate_heatmaps(global_idx)\n",
    "        \n",
    "        # 3x5 grid layout\n",
    "        row, col = 0, 0\n",
    "        for idx, heatmap in enumerate(self.heatmap_cache[global_idx]):\n",
    "            frame = ttk.Frame(container)\n",
    "            frame.grid(row=row, column=col, padx=5, pady=5)\n",
    "            \n",
    "            # Display single heatmap\n",
    "            self._show_single_heatmap(frame, idx, heatmap, global_idx)\n",
    "            \n",
    "            # Update grid position\n",
    "            col += 1\n",
    "            if col >= 5:  # 5 columns per row\n",
    "                col = 0\n",
    "                row += 1\n",
    "        \n",
    "        # Configure canvas scroll region\n",
    "        container.update_idletasks()\n",
    "        canvas.config(scrollregion=canvas.bbox(\"all\"))\n",
    "        \n",
    "        # Bind mouse wheel scrolling\n",
    "        canvas.bind(\"<MouseWheel>\", lambda e: canvas.yview_scroll(-1*(e.delta//120), \"units\"))\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_contour_overlay(heatmap, \n",
    "                                 original_image, \n",
    "                                 threshold=0.15, \n",
    "                                 contour_color=(0, 255, 0), \n",
    "                                 thickness=2):\n",
    "        \"\"\"\n",
    "        Draw contours based on Grad-CAM heatmap shape and overlay on original image.\n",
    "        \n",
    "        Parameters:\n",
    "            heatmap (numpy.ndarray): Grad-CAM heatmap, typically a 2D array.\n",
    "            original_image (numpy.ndarray): Original input image.\n",
    "            threshold (float): Binarization threshold, range [0, 1], default 0.15.\n",
    "            contour_color (tuple): Contour color, BGR format, default green.\n",
    "            thickness (int): Contour line thickness, default 2.\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: Original image with contours drawn.\n",
    "        \"\"\"\n",
    "        # Ensure heatmap is 2D\n",
    "        if heatmap.ndim != 2:\n",
    "            raise ValueError(\"Heatmap should be 2D\")\n",
    "        \n",
    "        # Normalize heatmap to 0-1 range\n",
    "        heatmap = (heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap) + 1e-8)\n",
    "        \n",
    "        # Apply threshold to create binary map\n",
    "        binary_map = heatmap > threshold\n",
    "        \n",
    "        # Find connected regions\n",
    "        contours, _ = cv2.findContours(binary_map.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Draw contours on original image\n",
    "        if contours:\n",
    "            cv2.drawContours(original_image, contours, -1, contour_color, thickness)\n",
    "        \n",
    "        return original_image\n",
    "    \n",
    "    def _generate_heatmaps(self, global_idx):\n",
    "        \"\"\"Generate and cache heatmaps\"\"\"\n",
    "        # Load model\n",
    "        if not self._load_heatmap_model():\n",
    "            return\n",
    "\n",
    "        # Get image data\n",
    "        img_tensor = self.dataset[global_idx].unsqueeze(0).to(self.cfg.device).float()\n",
    "        \n",
    "        # Generate heatmaps\n",
    "        Image_List = []\n",
    "        cam_map_List = []\n",
    "        \n",
    "        # Original image\n",
    "        img_np = np.array(self.tensor_to_pil(img_tensor.squeeze(0)))\n",
    "        Image_List.append(img_np)\n",
    "\n",
    "        # Individual attribute heatmaps\n",
    "        for k in range(12):\n",
    "            image_result, cam_map = show_heatmap_12dim(\n",
    "                img_tensor=img_tensor,\n",
    "                class_id=k,\n",
    "                dataset=self.dataset,\n",
    "                model_Dev=self.heatmap_model,\n",
    "                global_idx=global_idx,\n",
    "            )\n",
    "            Image_List.append(image_result)\n",
    "            cam_map_List.append(cam_map)\n",
    "\n",
    "        # Composite heatmap\n",
    "        sum_cam_map = np.zeros_like(cam_map_List[0])\n",
    "        for cam in cam_map_List[1:]:\n",
    "            sum_cam_map += cam\n",
    "        sum_cam_map = (sum_cam_map - sum_cam_map.min()) / (sum_cam_map.max() - sum_cam_map.min())\n",
    "        # Corrected to\n",
    "        img_path = self.dataset.image_paths[global_idx]  # Use correct attribute name\n",
    "        img_pil = Image.open(img_path)\n",
    "        sum_cam_map_image = overlay_mask(img_pil, Image.fromarray(cam_map), alpha=0.6) # Alpha determines original image transparency\n",
    "        Image_List.append(sum_cam_map_image)\n",
    "\n",
    "        # Generate image with contour\n",
    "        image_with_contour = ImageDatasetApp.generate_contour_overlay(\n",
    "            cam_map_List[3], \n",
    "            img_np.copy(),  # Use a copy of the original image\n",
    "            threshold=0.5,  # Adjust threshold\n",
    "            contour_color=(255, 0, 0),  # Red contour\n",
    "            thickness=2  # Contour line thickness\n",
    "        )\n",
    "        # print(\"Generated contour: \",image_with_contour.shape)\n",
    "\n",
    "        # Add generated image to Image_List\n",
    "        Image_List.append(image_with_contour)\n",
    "\n",
    "        # Cache results\n",
    "        self.heatmap_cache[global_idx] = Image_List\n",
    "        # print(f\"Heatmaps generated: {global_idx}\")\n",
    "\n",
    "    def _show_single_heatmap(self, parent, idx, heatmap, global_idx):\n",
    "        \"\"\"Display single heatmap cell (adjusted for grid layout)\"\"\"\n",
    "        frame = ttk.Frame(parent)\n",
    "        \n",
    "        # Adjust display size\n",
    "        display_size = 150  # Reduce display size to fit grid\n",
    "        if isinstance(heatmap, np.ndarray):\n",
    "            img = Image.fromarray(heatmap).resize((display_size, display_size))\n",
    "        else:\n",
    "            img = heatmap.resize((display_size, display_size))\n",
    "        \n",
    "        photo = ImageTk.PhotoImage(img)\n",
    "        \n",
    "        # List of attribute names\n",
    "        attr_names = [\n",
    "            'Original Image',                # 0\n",
    "            'Aesth_score',        # 1 -> Aesth_score\n",
    "            'balancing_ele',     # 2 -> balancing_ele\n",
    "            'color_harmony',          # 3 -> color_harmony \n",
    "            'content',                # 4 -> content\n",
    "            'depth_of_field',         # 5 -> depth_of_field\n",
    "            'light',          # 6 -> light\n",
    "            'motion_blur',            # 7 -> motion_blur\n",
    "            'object',           # 8 -> object\n",
    "            'repetition',             # 9 -> repetition\n",
    "            'rule_of_thirds',         # 10 -> rule_of_thirds\n",
    "            'symmetry',               # 11 -> symmetry\n",
    "            'vivid_color',            # 12 -> vivid_color\n",
    "            'Composite Score',                 # 13 (confirm existence of corresponding key)\n",
    "            'Box'\n",
    "        ]\n",
    "        \n",
    "        # Get scoring text\n",
    "        score_text = \"\"\n",
    "        if idx > 0:  # Skip original image\n",
    "            try:\n",
    "                scores = self.scores[global_idx]\n",
    "                # Convert attribute name to lowercase as key (e.g., Aesth -> aesth)\n",
    "                key = attr_names[idx]\n",
    "                score_text = f\"\\nScore: {scores[key]:.2f}\"\n",
    "            except (IndexError, KeyError) as e:\n",
    "                score_text = \"\\nScore: N/A\"\n",
    "                print(f\"Score retrieval error: {str(e)}\")\n",
    "\n",
    "        # Create label with scoring\n",
    "        label = ttk.Label(\n",
    "            frame, \n",
    "            image=photo, \n",
    "            text=f\"{attr_names[idx]}{score_text}\",\n",
    "            compound=\"top\", \n",
    "            padding=2,\n",
    "            font=('Microsoft YaHei', 11),  # Use clearer Chinese font\n",
    "            foreground='#333333'         # Dark gray text\n",
    "        )\n",
    "        label.image = photo\n",
    "        label.pack()\n",
    "            \n",
    "        \n",
    "        frame.pack()\n",
    "\n",
    "    def _load_heatmap_model(self):\n",
    "        \"\"\"Load heatmap generation model\"\"\"\n",
    "        try:\n",
    "            if self.heatmap_model is None:\n",
    "                # If no model path is selected, use the default path\n",
    "                if not hasattr(self, 'heatmap_model_path'):\n",
    "                    self.heatmap_model_path = '/home/zl/ä¸‹è½½/input/pykan-master/models/Data_argu/Data_argu_4_depth_of_field_epoch_8_loss_0.0548_grid_1_score_0.41242475441672044.pt'\n",
    "\n",
    "                # Initialize model\n",
    "                self.heatmap_model = RegressionNetwork_kan(\n",
    "                    backbone=cfg.models.backbone,\n",
    "                    num_attributes=12,\n",
    "                    pretrained=cfg.models.pretrained,\n",
    "                    kan=None,\n",
    "                ).to(self.cfg.device).eval()\n",
    "\n",
    "                # Load model weights\n",
    "                self.heatmap_model.load_state_dict(torch.load(self.heatmap_model_path))\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Failed to load heatmap model: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def _select_heatmap_model(self):\n",
    "        \"\"\"Select heatmap model file\"\"\"\n",
    "        initial_dir = '/home/zl/ä¸‹è½½/input/pykan-master/models'  # Default model directory\n",
    "        filetypes = [('PyTorch Model', '*.pt'), ('All Files', '*.*')]\n",
    "        \n",
    "        filepath = filedialog.askopenfilename(\n",
    "            title=\"Select Heatmap Model File\",\n",
    "            initialdir=initial_dir,\n",
    "            filetypes=filetypes\n",
    "        )\n",
    "        \n",
    "        if filepath:\n",
    "            if not filepath.endswith('.pt'):\n",
    "                messagebox.showwarning(\"Warning\", \"Please select a valid PyTorch model file (.pt)\")\n",
    "                return\n",
    "            \n",
    "            # Update model path\n",
    "            self.heatmap_model_path = filepath\n",
    "            self.heatmap_model = None  # Reset model instance\n",
    "            messagebox.showinfo(\"Info\", \"Model path updated, new model will be used for heatmap generation next time\")\n",
    "\n",
    "\n",
    "    def _show_score_info(self, parent, global_idx):\n",
    "        \"\"\"Display scoring information\"\"\"\n",
    "        score = self.scores[global_idx]\n",
    "        info = \"\\n\".join([\n",
    "            f\"Aesth: {score['Aesth_score']:.2f}\",\n",
    "            f\"Color: {score['color_harmony']:.2f}\",\n",
    "            f\"Composition: {score['rule_of_thirds']:.2f}\"\n",
    "        ])\n",
    "        \n",
    "        ttk.Label(parent,\n",
    "                text=info,\n",
    "                font=('Courier', 10),  # Increased font size\n",
    "                relief=\"groove\").pack(fill=tk.X, pady=2)\n",
    "\n",
    "    def _update_analysis_tab(self):\n",
    "        \"\"\"Update analysis tab content\"\"\"\n",
    "        # Clear old content\n",
    "        for widget in self.cluster_tab.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "        # Create new scroll container\n",
    "        container = self.setup_image_grid(self.cluster_tab)\n",
    "        \n",
    "        # Add title\n",
    "        ttk.Label(container, \n",
    "                text=f\"Cluster {self.current_cluster_id} Detailed Analysis\",\n",
    "                font=('Arial', 16, 'bold')).pack(pady=10)\n",
    "\n",
    "        # Get indices for the current cluster\n",
    "        indices = self.clusterID_get_indices[self.current_cluster_id]\n",
    "        \n",
    "        # Generate sorted index list\n",
    "        self.sorted_index_list = sorted(\n",
    "            indices,\n",
    "            key=lambda x: self.scores[x]['Aesth_score'],\n",
    "            reverse=True\n",
    "        )[:8]\n",
    "\n",
    "        # Display sorted images\n",
    "        grid_frame = ttk.Frame(container)\n",
    "        grid_frame.pack(pady=10)\n",
    "        \n",
    "        for idx, global_idx in enumerate(self.sorted_index_list):\n",
    "            self._create_analysis_image(grid_frame, global_idx, idx)\n",
    "\n",
    "\n",
    "    # Modify existing display method\n",
    "    def show_dataset(self):\n",
    "        \"\"\"Display dataset images\"\"\"\n",
    "        if not self.dataset:\n",
    "            messagebox.showwarning(\"Warning\", \"Please create the dataset first!\")\n",
    "            return\n",
    "\n",
    "        self.clear_display()\n",
    "        self.create_image_grid(self.dataset)\n",
    "\n",
    "\n",
    "    def create_image_grid(self, dataset):\n",
    "        \"\"\"Create image grid with scoring\"\"\"\n",
    "        container = self.main_container\n",
    "        cols = 4  # Reduce number of columns to accommodate more information\n",
    "        \n",
    "        for idx in range(len(dataset)):\n",
    "            row = idx // cols\n",
    "            col = idx % cols\n",
    "            \n",
    "            if col == 0:\n",
    "                row_frame = tk.Frame(container)\n",
    "                row_frame.pack(pady=5, anchor='w')\n",
    "\n",
    "            cell = self._create_image_cell(row_frame, dataset, idx)\n",
    "            cell.grid(row=0, column=col, padx=5)\n",
    "\n",
    "    def tensor_to_pil(self, tensor):\n",
    "        \"\"\"Convert tensor to PIL image\"\"\"\n",
    "        # Handle different tensor shapes\n",
    "        if tensor.dim() == 4:\n",
    "            tensor = tensor.squeeze(0)\n",
    "        if tensor.size(0) > 3:\n",
    "            tensor = tensor[:3]\n",
    "        \n",
    "        # Reverse normalization\n",
    "        if tensor.min() < 0 or tensor.max() > 1:\n",
    "            tensor = (tensor - tensor.min()) / (tensor.max() - tensor.min())\n",
    "        \n",
    "        return T.ToPILImage()(tensor)\n",
    "\n",
    "    def clear_display(self):\n",
    "        \"\"\"Clear display area\"\"\"\n",
    "        for widget in self.main_container.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "    def on_mousewheel(self, event):\n",
    "        \"\"\"Handle mouse wheel scrolling\"\"\"\n",
    "        self.canvas.yview_scroll(-1*(event.delta//120), \"units\")\n",
    "\n",
    "    @staticmethod\n",
    "    def create_data_loader(path):\n",
    "        \"\"\"Create data loader (migrated from user code)\"\"\"\n",
    "        transform = T.Compose([\n",
    "            T.Resize((256, 256)),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        class CustomDataset(Dataset):\n",
    "            def __init__(self, root_dir, transform=None, max_samples=1000):\n",
    "                self.root_dir = root_dir\n",
    "                self.transform = transform\n",
    "                self.image_paths = self._load_paths(max_samples)\n",
    "\n",
    "            def _load_paths(self, max_samples):\n",
    "                valid_ext = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff')\n",
    "                return [\n",
    "                    os.path.join(self.root_dir, f) \n",
    "                    for f in os.listdir(self.root_dir)[:max_samples] \n",
    "                    if f.lower().endswith(valid_ext)\n",
    "                ]\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.image_paths)\n",
    "\n",
    "            def __getitem__(self, idx):\n",
    "                try:\n",
    "                    img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "                    return self.transform(img) if self.transform else img\n",
    "                except:\n",
    "                    return torch.zeros(3, 256, 256)\n",
    "\n",
    "        dataset = CustomDataset(path, transform=transform)\n",
    "        dataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "        return dataset, dataloader\n",
    "    def setup_image_grid(self, parent):\n",
    "        \"\"\"Optimize Image Display Area\"\"\"\n",
    "        # Scroll system\n",
    "        canvas = tk.Canvas(parent, bg=self.colors['background'])\n",
    "        scroll_y = ttk.Scrollbar(parent, orient=tk.VERTICAL, command=canvas.yview)\n",
    "        scroll_x = ttk.Scrollbar(parent, orient=tk.HORIZONTAL, command=canvas.xview)\n",
    "        \n",
    "        canvas.configure(\n",
    "            yscrollcommand=scroll_y.set,\n",
    "            xscrollcommand=scroll_x.set\n",
    "        )\n",
    "        \n",
    "        # Layout\n",
    "        scroll_x.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "        scroll_y.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Image container\n",
    "        self.main_container = ttk.Frame(canvas)\n",
    "        canvas.create_window((0, 0), window=self.main_container, anchor=tk.NW)\n",
    "\n",
    "        # Event binding\n",
    "        self.main_container.bind(\"<Configure>\", \n",
    "            lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "    \n",
    "    def _create_image_cell(self, parent, dataset, idx):\n",
    "        \"\"\"Create Single Image Cell\"\"\"\n",
    "        cell = tk.Frame(parent, width=150, height=170, \n",
    "                    borderwidth=1, relief='groove')\n",
    "        \n",
    "        try:\n",
    "            # Display image\n",
    "            tensor = dataset[idx]\n",
    "            img = self.tensor_to_pil(tensor)\n",
    "            img.thumbnail((140, 140))\n",
    "            photo = ImageTk.PhotoImage(img)\n",
    "            \n",
    "            img_label = tk.Label(cell, image=photo)\n",
    "            img_label.image = photo\n",
    "            img_label.pack()\n",
    "            \n",
    "            # Display score\n",
    "            if idx < len(self.scores):\n",
    "                score = self.scores[idx]['Aesth_score']\n",
    "                tk.Label(cell, \n",
    "                        text=f\"Score: {score:.2f}\",\n",
    "                        bg='#FFD700', fg='black',\n",
    "                        font=('Arial', 11)).pack(fill=tk.X)  # Increased font size\n",
    "                    \n",
    "        except Exception as e:\n",
    "            tk.Label(cell, text=f\"Error\\n{str(e)[:15]}\", fg='red').pack()\n",
    "        \n",
    "        return cell\n",
    "\n",
    "\n",
    "    def load_folder(self):\n",
    "        \"\"\"Load Image Folder\"\"\"\n",
    "        path = filedialog.askdirectory()\n",
    "        if path:\n",
    "            self.current_path = path\n",
    "            self.path_label.config(text=f\"Current Path: {path[:50]}...\")\n",
    "            messagebox.showinfo(\"Info\", f\"Successfully loaded path: {path}\")\n",
    "\n",
    "    def create_dataset(self):\n",
    "        \"\"\"Create Dataset and Data Loader\"\"\"\n",
    "        if not self.current_path:\n",
    "            messagebox.showwarning(\"Warning\", \"Please select an image folder first!\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            self.dataset, self.dataloader = self.create_data_loader(self.current_path)\n",
    "            messagebox.showinfo(\"Success\", \n",
    "                f\"Dataset creation completed!\\n\"\n",
    "                f\"Number of samples: {len(self.dataset)}\\n\"\n",
    "                f\"Batch shape: {next(iter(self.dataloader)).shape}\")\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Failed to create dataset: {str(e)}\")\n",
    "\n",
    "    def create_image_grid(self, dataset):\n",
    "        \"\"\"Create Image Grid with Scoring\"\"\"\n",
    "        container = self.main_container\n",
    "        cols = 4  # Reduce number of columns to accommodate more information\n",
    "        \n",
    "        for idx in range(len(dataset)):\n",
    "            row = idx // cols\n",
    "            col = idx % cols\n",
    "            \n",
    "            if col == 0:\n",
    "                row_frame = tk.Frame(container)\n",
    "                row_frame.pack(pady=5, anchor='w')\n",
    "\n",
    "            cell = self._create_image_cell(row_frame, dataset, idx)\n",
    "            cell.grid(row=0, column=col, padx=5)\n",
    "\n",
    "    def tensor_to_pil(self, tensor):\n",
    "        \"\"\"Convert Tensor to PIL Image\"\"\"\n",
    "        # Handle different tensor shapes\n",
    "        if tensor.dim() == 4:\n",
    "            tensor = tensor.squeeze(0)\n",
    "        if tensor.size(0) > 3:\n",
    "            tensor = tensor[:3]\n",
    "        \n",
    "        # Reverse normalization\n",
    "        if tensor.min() < 0 or tensor.max() > 1:\n",
    "            tensor = (tensor - tensor.min()) / (tensor.max() - tensor.min())\n",
    "        \n",
    "        return T.ToPILImage()(tensor)\n",
    "\n",
    "    def clear_display(self):\n",
    "        \"\"\"Clear Display Area\"\"\"\n",
    "        for widget in self.main_container.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "    def on_mousewheel(self, event):\n",
    "        \"\"\"Handle Mouse Wheel Scrolling\"\"\"\n",
    "        self.canvas.yview_scroll(-1 * (event.delta // 120), \"units\")\n",
    "\n",
    "    @staticmethod\n",
    "    def create_data_loader(path):\n",
    "        \"\"\"Create Data Loader\"\"\"\n",
    "        transform = T.Compose([\n",
    "            T.Resize((256, 256)),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        class CustomDataset(Dataset):\n",
    "            def __init__(self, root_dir, transform=None, max_samples=1000):\n",
    "                self.root_dir = root_dir\n",
    "                self.transform = transform\n",
    "                self.image_paths = self._load_paths(max_samples)\n",
    "\n",
    "            def _load_paths(self, max_samples):\n",
    "                valid_ext = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff')\n",
    "                return [\n",
    "                    os.path.join(self.root_dir, f) \n",
    "                    for f in os.listdir(self.root_dir)[:max_samples] \n",
    "                    if f.lower().endswith(valid_ext)\n",
    "                ]\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.image_paths)\n",
    "\n",
    "            def __getitem__(self, idx):\n",
    "                try:\n",
    "                    img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "                    return self.transform(img) if self.transform else img\n",
    "                except:\n",
    "                    return torch.zeros(3, 256, 256)\n",
    "\n",
    "        dataset = CustomDataset(path, transform=transform)\n",
    "        dataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "        return dataset, dataloader\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = ImageDatasetApp(root)\n",
    "    root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-zh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
